{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dc6e2ed",
   "metadata": {},
   "source": [
    "# üìä Chapter 04: scikit-learn - Machine Learning with Multiple Datasets\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "By the end of this chapter, you will:\n",
    "- ‚úÖ Understand scikit-learn's estimator API and workflow\n",
    "- ‚úÖ Build classification models (predict categories)\n",
    "- ‚úÖ Build regression models (predict numbers)\n",
    "- ‚úÖ Apply ML techniques on **3 different datasets**\n",
    "- ‚úÖ Evaluate model performance with metrics\n",
    "- ‚úÖ Perform cross-validation and hyperparameter tuning\n",
    "\n",
    "---\n",
    "\n",
    "## üìÅ Datasets Used\n",
    "\n",
    "### 1Ô∏è‚É£ Iris Flowers (Classification)\n",
    "**Purpose**: Classify flower species\n",
    "- 150 samples, 4 features\n",
    "- 3 classes (Setosa, Versicolor, Virginica)\n",
    "\n",
    "### 2Ô∏è‚É£ Wine Quality (Classification)\n",
    "**Purpose**: Classify wine types\n",
    "- 178 samples, 13 features\n",
    "- 3 classes of wine\n",
    "\n",
    "### 3Ô∏è‚É£ California Housing (Regression)\n",
    "**Purpose**: Predict house prices\n",
    "- 20,640 samples, 8 features\n",
    "- Continuous target (price)\n",
    "\n",
    "**Why 3 datasets?** Practice both classification AND regression!\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Table of Contents\n",
    "**0.5. [scikit-learn Basics - Essential ML Concepts](#sklearn-basics)** ‚≠ê **Start Here! Learn ML concepts BEFORE building models**\n",
    "1. [Introduction to scikit-learn](#intro)\n",
    "2. [Loading Datasets](#loading)\n",
    "3. [Train/Test Split](#split)\n",
    "4. [Data Preprocessing](#preprocessing)\n",
    "5. [Classification Models](#classification)\n",
    "6. [Regression Models](#regression)\n",
    "7. [Model Evaluation](#evaluation)\n",
    "8. [Cross-Validation](#cv)\n",
    "9. [Pipelines](#pipelines)\n",
    "10. [Practice Exercises](#exercises)\n",
    "11. [Next Steps: Projects](#projects)\n",
    "\n",
    "üí° **Tip for Beginners**: Section 0.5 teaches you train_test_split, StandardScaler, fit/predict, cross-validation, and more BEFORE we build models. Don't skip it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a613c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn version: 1.7.2\n",
      "NumPy version: 2.3.1\n",
      "pandas version: 2.3.0\n",
      "\n",
      "‚úÖ All libraries imported successfully!\n",
      "\n",
      "üéØ Ready to build machine learning models!\n"
     ]
    }
   ],
   "source": [
    "# Import core scikit-learn modules\n",
    "# sklearn.datasets - Built-in datasets for practice\n",
    "from sklearn.datasets import load_iris, load_wine, fetch_california_housing\n",
    "\n",
    "# sklearn.model_selection - Train/test split, cross-validation\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "\n",
    "# sklearn.preprocessing - Data scaling and transformation\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# sklearn.linear_model - Linear models (Linear Regression, Logistic Regression)\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "\n",
    "# sklearn.ensemble - Ensemble methods (Random Forest, Gradient Boosting)\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "# sklearn.metrics - Model evaluation metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# sklearn.pipeline - Creating ML pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Import supporting libraries\n",
    "import numpy as np  # For numerical operations\n",
    "import pandas as pd  # For data manipulation\n",
    "import matplotlib.pyplot as plt  # For visualization\n",
    "import seaborn as sns  # For statistical plots\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "# This ensures we get same results every time we run the code\n",
    "np.random.seed(42)\n",
    "\n",
    "# Check versions\n",
    "import sklearn\n",
    "print(f\"scikit-learn version: {sklearn.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"pandas version: {pd.__version__}\")\n",
    "print(\"\\n‚úÖ All libraries imported successfully!\")\n",
    "print(\"\\nüéØ Ready to build machine learning models!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4e331a",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"sklearn-basics\"></a>\n",
    "## 0.5 scikit-learn Basics - Essential ML Concepts üîë\n",
    "\n",
    "**‚ö†Ô∏è CRITICAL FOR BEGINNERS**: This section introduces ALL fundamental machine learning concepts **BEFORE** we build models. Don't skip this - it's the foundation for everything that follows!\n",
    "\n",
    "---\n",
    "\n",
    "### üìå Concept 1: Features (X) and Target (y)\n",
    "\n",
    "In machine learning, we have two types of data:\n",
    "\n",
    "**Features (X)** - Input variables (predictors, independent variables):\n",
    "- These are the measurements or characteristics we know\n",
    "- Always a 2D array: shape `(n_samples, n_features)`\n",
    "- Example: Height, weight, age ‚Üí predict diabetes\n",
    "- Convention: Capital `X`\n",
    "\n",
    "**Target (y)** - Output variable (label, dependent variable):\n",
    "- This is what we want to predict\n",
    "- Always a 1D array: shape `(n_samples,)`\n",
    "- Example: Disease presence (yes/no), house price ($)\n",
    "- Convention: Lowercase `y`\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "# Predicting flower species\n",
    "X = [[5.1, 3.5, 1.4, 0.2],  # Sample 1: 4 features\n",
    "     [4.9, 3.0, 1.4, 0.2],  # Sample 2: 4 features\n",
    "     [6.3, 2.5, 5.0, 1.9]]  # Sample 3: 4 features\n",
    "# X.shape = (3, 4) ‚Üí 3 samples, 4 features\n",
    "\n",
    "y = [0, 0, 2]  # Species: setosa, setosa, virginica\n",
    "# y.shape = (3,) ‚Üí 3 labels\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üìå Concept 2: Classification vs Regression\n",
    "\n",
    "Two main types of machine learning problems:\n",
    "\n",
    "| Type | Target Variable | Example | Algorithms |\n",
    "|------|----------------|---------|------------|\n",
    "| **Classification** | **Categorical** (discrete classes) | Spam/Not spam<br>Dog/Cat/Bird<br>Survived/Died | Logistic Regression<br>Random Forest Classifier<br>SVM |\n",
    "| **Regression** | **Continuous** (numbers) | House price ($)<br>Temperature (¬∞C)<br>Stock price | Linear Regression<br>Random Forest Regressor<br>Neural Networks |\n",
    "\n",
    "**How to tell:**\n",
    "- Can you list all possible values? ‚Üí **Classification**\n",
    "- Is it a number on a continuous scale? ‚Üí **Regression**\n",
    "\n",
    "---\n",
    "\n",
    "### üìå Concept 3: Train/Test Split\n",
    "\n",
    "**Why split data?**\n",
    "- **Training set**: Model learns patterns from this data\n",
    "- **Test set**: Model evaluated on unseen data (measures real-world performance)\n",
    "- **Never test on training data!** Model will just memorize, not learn\n",
    "\n",
    "**Common split ratios:**\n",
    "- 80% train, 20% test (most common)\n",
    "- 70% train, 30% test\n",
    "- 90% train, 10% test (if data is large)\n",
    "\n",
    "**How to split:**\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,      # 20% for testing\n",
    "    random_state=42     # For reproducibility\n",
    ")\n",
    "```\n",
    "\n",
    "**Understanding the output:**\n",
    "- `X_train`: Training features (80% of data)\n",
    "- `X_test`: Test features (20% of data)\n",
    "- `y_train`: Training labels (80% of data)\n",
    "- `y_test`: Test labels (20% of data)\n",
    "\n",
    "**Random state:**\n",
    "- `random_state=42` ensures same split every time (reproducible results)\n",
    "- Without it, split is different each run\n",
    "\n",
    "---\n",
    "\n",
    "### üìå Concept 4: Data Preprocessing - Scaling\n",
    "\n",
    "**Why scale features?**\n",
    "- Features often have different ranges: Age (0-100) vs Income (0-1,000,000)\n",
    "- Many ML algorithms (SVM, Neural Networks, KNN) perform poorly with different scales\n",
    "- Scaling puts all features on same scale (usually 0-1 or mean=0, std=1)\n",
    "\n",
    "**Common scaling methods:**\n",
    "\n",
    "| Method | Formula | Range | Use when |\n",
    "|--------|---------|-------|----------|\n",
    "| **StandardScaler** | `(x - mean) / std` | Mean=0, Std=1 | Default choice, data is normally distributed |\n",
    "| **MinMaxScaler** | `(x - min) / (max - min)` | [0, 1] | Data has clear min/max bounds |\n",
    "| **RobustScaler** | Uses median/IQR | No fixed range | Data has outliers |\n",
    "\n",
    "**How to scale:**\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Fit on train, transform train\n",
    "X_test_scaled = scaler.transform(X_test)        # Transform test (using train stats)\n",
    "```\n",
    "\n",
    "**CRITICAL: fit on train, transform on test!**\n",
    "- `fit_transform()` on training data ‚Üí learns mean/std from training data\n",
    "- `transform()` on test data ‚Üí uses training mean/std (not test mean/std!)\n",
    "- This prevents data leakage from test set\n",
    "\n",
    "---\n",
    "\n",
    "### üìå Concept 5: The scikit-learn API - fit, predict, score\n",
    "\n",
    "**All scikit-learn estimators follow the same pattern:**\n",
    "\n",
    "#### 1. **Create model** (instantiate estimator)\n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()  # Create model with default parameters\n",
    "```\n",
    "\n",
    "#### 2. **Train model** (fit on training data)\n",
    "```python\n",
    "model.fit(X_train, y_train)  # Model learns from training data\n",
    "```\n",
    "\n",
    "#### 3. **Make predictions** (predict on new data)\n",
    "```python\n",
    "y_pred = model.predict(X_test)  # Predict labels for test data\n",
    "```\n",
    "\n",
    "#### 4. **Evaluate model** (score or metrics)\n",
    "```python\n",
    "accuracy = model.score(X_test, y_test)  # Returns accuracy for classifiers\n",
    "```\n",
    "\n",
    "**Key methods:**\n",
    "\n",
    "| Method | Purpose | Example |\n",
    "|--------|---------|---------|\n",
    "| `.fit(X, y)` | Train model | `model.fit(X_train, y_train)` |\n",
    "| `.predict(X)` | Make predictions | `y_pred = model.predict(X_test)` |\n",
    "| `.score(X, y)` | Evaluate model | `accuracy = model.score(X_test, y_test)` |\n",
    "| `.predict_proba(X)` | Class probabilities (classifiers) | `probs = model.predict_proba(X_test)` |\n",
    "\n",
    "---\n",
    "\n",
    "### üìå Concept 6: Model Evaluation Metrics\n",
    "\n",
    "**Classification metrics:**\n",
    "\n",
    "| Metric | What it measures | Range | Higher = Better? |\n",
    "|--------|-----------------|-------|------------------|\n",
    "| **Accuracy** | % correct predictions | 0-1 (or 0-100%) | ‚úÖ Yes |\n",
    "| **Precision** | Of predicted positives, % actually positive | 0-1 | ‚úÖ Yes |\n",
    "| **Recall** | Of actual positives, % predicted positive | 0-1 | ‚úÖ Yes |\n",
    "| **F1-Score** | Harmonic mean of precision & recall | 0-1 | ‚úÖ Yes |\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "```\n",
    "\n",
    "**Regression metrics:**\n",
    "\n",
    "| Metric | What it measures | Range | Lower = Better? |\n",
    "|--------|-----------------|-------|-----------------|\n",
    "| **MSE** (Mean Squared Error) | Average squared error | 0-‚àû | ‚úÖ Yes |\n",
    "| **RMSE** (Root MSE) | Average error in original units | 0-‚àû | ‚úÖ Yes |\n",
    "| **MAE** (Mean Absolute Error) | Average absolute error | 0-‚àû | ‚úÖ Yes |\n",
    "| **R¬≤ Score** | % variance explained | -‚àû to 1 | ‚ùå No (higher is better) |\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)  # squared=False ‚Üí RMSE\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üìå Concept 7: Cross-Validation\n",
    "\n",
    "**Problem with single train/test split:**\n",
    "- Results depend on which data points ended up in train vs test\n",
    "- One \"lucky\" split might give misleadingly good results\n",
    "\n",
    "**Solution: K-Fold Cross-Validation**\n",
    "\n",
    "**How it works:**\n",
    "1. Split data into K folds (usually K=5 or K=10)\n",
    "2. Train on K-1 folds, test on remaining fold\n",
    "3. Repeat K times (each fold gets to be test set once)\n",
    "4. Average results from all K iterations\n",
    "\n",
    "**Example: 5-Fold CV**\n",
    "```\n",
    "Iteration 1: Train [2,3,4,5], Test [1]\n",
    "Iteration 2: Train [1,3,4,5], Test [2]\n",
    "Iteration 3: Train [1,2,4,5], Test [3]\n",
    "Iteration 4: Train [1,2,3,5], Test [4]\n",
    "Iteration 5: Train [1,2,3,4], Test [5]\n",
    "```\n",
    "\n",
    "**How to use:**\n",
    "```python\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=5)  # 5-fold CV\n",
    "print(f\"Average accuracy: {scores.mean():.3f} (+/- {scores.std():.3f})\")\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "- More reliable performance estimate\n",
    "- Uses all data for both training and testing\n",
    "- Shows variance in model performance\n",
    "\n",
    "---\n",
    "\n",
    "### üìå Concept 8: Hyperparameter Tuning\n",
    "\n",
    "**Hyperparameters** = Settings you choose **before** training:\n",
    "- NOT learned from data\n",
    "- Examples: Number of trees in Random Forest, learning rate, max depth\n",
    "\n",
    "**Problem:** Wrong hyperparameters ‚Üí poor performance\n",
    "\n",
    "**Solution: Grid Search**\n",
    "\n",
    "**How it works:**\n",
    "1. Define grid of hyperparameter values to try\n",
    "2. Try every combination using cross-validation\n",
    "3. Return best combination\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100],      # 3 values\n",
    "    'max_depth': [None, 10, 20]         # 3 values\n",
    "}\n",
    "# Total: 3 √ó 3 = 9 combinations\n",
    "\n",
    "# Create grid search\n",
    "grid = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üìå Concept 9: Pipelines\n",
    "\n",
    "**Problem:** Many steps to remember:\n",
    "1. Scale data\n",
    "2. Train model\n",
    "3. Don't forget to scale test data the same way!\n",
    "\n",
    "**Solution: Pipeline** (automates the workflow)\n",
    "\n",
    "**How it works:**\n",
    "```python\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),      # Step 1: Scale\n",
    "    ('classifier', LogisticRegression())  # Step 2: Classify\n",
    "])\n",
    "\n",
    "# Train (automatically scales then trains)\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict (automatically scales then predicts)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "- Less code, fewer bugs\n",
    "- Prevents data leakage (can't forget to scale test data)\n",
    "- Easy to use with GridSearchCV\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Quick Reference Summary\n",
    "\n",
    "| Concept | Code Example |\n",
    "|---------|-------------|\n",
    "| **Train/test split** | `X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)` |\n",
    "| **Scale data** | `scaler = StandardScaler()`<br>`X_scaled = scaler.fit_transform(X_train)` |\n",
    "| **Create model** | `model = LogisticRegression()` |\n",
    "| **Train model** | `model.fit(X_train, y_train)` |\n",
    "| **Make predictions** | `y_pred = model.predict(X_test)` |\n",
    "| **Evaluate** | `accuracy = model.score(X_test, y_test)` |\n",
    "| **Cross-validation** | `scores = cross_val_score(model, X, y, cv=5)` |\n",
    "| **Grid search** | `grid = GridSearchCV(model, param_grid, cv=5)`<br>`grid.fit(X_train, y_train)` |\n",
    "| **Pipeline** | `pipe = Pipeline([('scaler', StandardScaler()), ('model', LogisticRegression())])` |\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Why This Section Matters\n",
    "\n",
    "In the sections that follow, you'll see code like:\n",
    "- `train_test_split(X, y, test_size=0.2)` ‚Üí Now you know this splits data 80/20!\n",
    "- `scaler.fit_transform(X_train)` ‚Üí Now you know this learns from and transforms training data!\n",
    "- `model.fit(X_train, y_train)` ‚Üí Now you know this trains the model!\n",
    "- `model.predict(X_test)` ‚Üí Now you know this makes predictions on new data!\n",
    "- `cross_val_score(model, X, y, cv=5)` ‚Üí Now you know this does 5-fold cross-validation!\n",
    "\n",
    "**‚úÖ You're now ready to build machine learning models!** Let's practice these concepts below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a1148d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SCIKIT-LEARN & MACHINE LEARNING BASICS - HANDS-ON PRACTICE\n",
      "================================================================================\n",
      "\n",
      "üìå PRACTICE 1: Understanding Features (X) and Target (y)\n",
      "--------------------------------------------------------------------------------\n",
      "Features (X) shape: (100, 4)\n",
      "  ‚Üí 100 samples (rows)\n",
      "  ‚Üí 4 features (columns)\n",
      "\n",
      "Target (y) shape: (100,)\n",
      "  ‚Üí 100 labels (one per sample)\n",
      "\n",
      "First 3 samples:\n",
      "X[0:3] = \n",
      "[[-0.0550468  -0.16181908 -0.07689964  1.01423611]\n",
      " [-0.45497224  0.24301397  0.02138859 -0.77621682]\n",
      " [-0.68374687  0.51321414  0.13464353 -1.75251746]]\n",
      "y[0:3] = [1 0 0]\n",
      "\n",
      "‚úÖ X is 2D (samples √ó features), y is 1D (labels)\n",
      "\n",
      "\n",
      "üìå PRACTICE 2: Classification vs Regression\n",
      "--------------------------------------------------------------------------------\n",
      "CLASSIFICATION: Predicting categories\n",
      "Target values (first 10): [0 1 1 0 0 0 2 0 1 0]\n",
      "Unique classes: [0 1 2]\n",
      "Example: Predicting flower species (Setosa, Versicolor, Virginica)\n",
      "\n",
      "\n",
      "REGRESSION: Predicting numbers\n",
      "Target values (first 10): [  42.43   37.84  155.36 -115.92  171.55 -121.05  -55.4  -105.76  -30.08\n",
      " -123.33]\n",
      "Range: -228.00 to 190.73\n",
      "Example: Predicting house prices ($100,000 to $500,000)\n",
      "\n",
      "‚úÖ Classification ‚Üí Categories (0, 1, 2)\n",
      "‚úÖ Regression ‚Üí Continuous numbers (123.45, -67.89)\n",
      "\n",
      "\n",
      "üìå PRACTICE 3: Train/Test Split\n",
      "--------------------------------------------------------------------------------\n",
      "Original data: 100 samples\n",
      "\n",
      "After split:\n",
      "  X_train shape: (80, 4) (80% = 80 samples)\n",
      "  X_test shape:  (20, 4) (20% = 20 samples)\n",
      "  y_train shape: (80,)\n",
      "  y_test shape:  (20,)\n",
      "\n",
      "‚úÖ Train on 80%, Test on 20% (never test on training data!)\n",
      "\n",
      "With same random_state=42:\n",
      "  Are splits identical? True\n",
      "\n",
      "With different random_state=99:\n",
      "  Are splits identical? False\n",
      "\n",
      "\n",
      "üìå PRACTICE 4: Data Scaling with StandardScaler\n",
      "--------------------------------------------------------------------------------\n",
      "BEFORE scaling:\n",
      "[[1.e+00 1.e+03 5.e-01]\n",
      " [5.e+00 5.e+03 7.e-01]\n",
      " [1.e+01 1.e+04 9.e-01]]\n",
      "\n",
      "Feature 1 range: 1.0 to 10.0\n",
      "Feature 2 range: 1000.0 to 10000.0\n",
      "Feature 3 range: 0.5 to 0.9\n",
      "\n",
      "\n",
      "AFTER StandardScaler:\n",
      "[[-1.177 -1.177 -1.225]\n",
      " [-0.091 -0.091 -0.   ]\n",
      " [ 1.268  1.268  1.225]]\n",
      "\n",
      "All features now have:\n",
      "  Mean ‚âà 0: [ 0.  0. -0.]\n",
      "  Std ‚âà 1:  [1. 1. 1.]\n",
      "\n",
      "‚úÖ StandardScaler: (x - mean) / std ‚Üí Mean=0, Std=1\n",
      "\n",
      "\n",
      "üìå PRACTICE 5: fit_transform vs transform (CRITICAL!)\n",
      "--------------------------------------------------------------------------------\n",
      "CORRECT approach:\n",
      "X_train (original): [1 2 3 4 5]\n",
      "X_train (scaled):   [-1.414 -0.707  0.     0.707  1.414]\n",
      "  ‚Üí fit_transform() learns mean=3.0, std=1.41\n",
      "\n",
      "X_test (original): [6 7]\n",
      "X_test (scaled):   [2.121 2.828]\n",
      "  ‚Üí transform() uses training mean=3.0, std=1.41\n",
      "\n",
      "\n",
      "‚ùå WRONG: fit_transform on test\n",
      "X_test (scaled wrong): [-1.  1.]\n",
      "  ‚Üí Uses test mean=6.5, std=0.50\n",
      "  ‚Üí This is DATA LEAKAGE! Never fit on test data!\n",
      "\n",
      "\n",
      "‚úÖ RULE: fit_transform(train), transform(test)\n",
      "\n",
      "\n",
      "üìå PRACTICE 6: scikit-learn API - fit, predict, score\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1: CREATE model\n",
      "  model = LogisticRegression()\n",
      "\n",
      "Step 2: TRAIN model (fit)\n",
      "  model.fit(X_train, y_train)\n",
      "  ‚Üí Model learned from 4 training samples\n",
      "\n",
      "Step 3: PREDICT on new data\n",
      "  y_pred = model.predict(X_test)\n",
      "  ‚Üí Predictions: [0 0]\n",
      "  ‚Üí Actual:      [0 0]\n",
      "\n",
      "Step 4: EVALUATE model (score)\n",
      "  accuracy = model.score(X_test, y_test)\n",
      "  ‚Üí Accuracy: 100.00%\n",
      "\n",
      "‚úÖ All scikit-learn models: CREATE ‚Üí FIT ‚Üí PREDICT ‚Üí SCORE\n",
      "\n",
      "\n",
      "üìå PRACTICE 7: Classification Metrics\n",
      "--------------------------------------------------------------------------------\n",
      "True labels:       [0 0 1 1 1 0 1 0 1 1]\n",
      "Predicted labels:  [0 0 1 1 0 0 1 1 1 1]\n",
      "\n",
      "Accuracy: 80.00%\n",
      "  ‚Üí 8 out of 10 predictions correct\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3 1]\n",
      " [1 5]]\n",
      "        Predicted\n",
      "           0  1\n",
      "Actual 0  3  1\n",
      "       1  1  5\n",
      "\n",
      "‚úÖ Accuracy = (Correct predictions) / (Total predictions)\n",
      "\n",
      "\n",
      "üìå PRACTICE 8: Regression Metrics\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "got an unexpected keyword argument 'squared'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 235\u001b[39m\n\u001b[32m    232\u001b[39m y_pred = np.array([\u001b[32m110\u001b[39m, \u001b[32m190\u001b[39m, \u001b[32m310\u001b[39m, \u001b[32m390\u001b[39m, \u001b[32m510\u001b[39m])\n\u001b[32m    234\u001b[39m mse = mean_squared_error(y_true, y_pred)\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m rmse = \u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    236\u001b[39m mae = mean_absolute_error(y_true, y_pred)\n\u001b[32m    237\u001b[39m r2 = r2_score(y_true, y_pred)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\_param_validation.py:196\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    193\u001b[39m func_sig = signature(func)\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m params = \u001b[43mfunc_sig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    197\u001b[39m params.apply_defaults()\n\u001b[32m    199\u001b[39m \u001b[38;5;66;03m# ignore self/cls and positional/keyword markers\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\inspect.py:3280\u001b[39m, in \u001b[36mSignature.bind\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3275\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, /, *args, **kwargs):\n\u001b[32m   3276\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[32m   3277\u001b[39m \u001b[33;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[32m   3278\u001b[39m \u001b[33;03m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[32m   3279\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3280\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\inspect.py:3269\u001b[39m, in \u001b[36mSignature._bind\u001b[39m\u001b[34m(self, args, kwargs, partial)\u001b[39m\n\u001b[32m   3259\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   3260\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mgot some positional-only arguments passed as \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   3261\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mkeyword arguments: \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[33m'\u001b[39m.format(\n\u001b[32m   (...)\u001b[39m\u001b[32m   3266\u001b[39m             ),\n\u001b[32m   3267\u001b[39m         )\n\u001b[32m   3268\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3269\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   3270\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mgot an unexpected keyword argument \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[33m'\u001b[39m.format(\n\u001b[32m   3271\u001b[39m                 arg=\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(kwargs))))\n\u001b[32m   3273\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_arguments_cls(\u001b[38;5;28mself\u001b[39m, arguments)\n",
      "\u001b[31mTypeError\u001b[39m: got an unexpected keyword argument 'squared'"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# HANDS-ON PRACTICE: scikit-learn & ML Basics\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SCIKIT-LEARN & MACHINE LEARNING BASICS - HANDS-ON PRACTICE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# PRACTICE 1: Features (X) and Target (y)\n",
    "# ============================================================================\n",
    "print(\"\\nüìå PRACTICE 1: Understanding Features (X) and Target (y)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Create sample data\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=100, n_features=4, n_informative=3,\n",
    "                           n_redundant=1, random_state=42)\n",
    "\n",
    "print(f\"Features (X) shape: {X.shape}\")\n",
    "print(f\"  ‚Üí {X.shape[0]} samples (rows)\")\n",
    "print(f\"  ‚Üí {X.shape[1]} features (columns)\")\n",
    "print(f\"\\nTarget (y) shape: {y.shape}\")\n",
    "print(f\"  ‚Üí {y.shape[0]} labels (one per sample)\")\n",
    "print(f\"\\nFirst 3 samples:\")\n",
    "print(f\"X[0:3] = \\n{X[0:3]}\")\n",
    "print(f\"y[0:3] = {y[0:3]}\")\n",
    "print(f\"\\n‚úÖ X is 2D (samples √ó features), y is 1D (labels)\")\n",
    "\n",
    "# ============================================================================\n",
    "# PRACTICE 2: Classification vs Regression\n",
    "# ============================================================================\n",
    "print(\"\\n\\nüìå PRACTICE 2: Classification vs Regression\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Classification: Categorical target\n",
    "from sklearn.datasets import make_classification\n",
    "X_class, y_class = make_classification(n_samples=50, n_classes=3, n_informative=3, \n",
    "                                       n_redundant=0, random_state=42)\n",
    "\n",
    "print(\"CLASSIFICATION: Predicting categories\")\n",
    "print(f\"Target values (first 10): {y_class[:10]}\")\n",
    "print(f\"Unique classes: {np.unique(y_class)}\")  # [0, 1, 2]\n",
    "print(\"Example: Predicting flower species (Setosa, Versicolor, Virginica)\")\n",
    "\n",
    "# Regression: Continuous target\n",
    "from sklearn.datasets import make_regression\n",
    "X_reg, y_reg = make_regression(n_samples=50, n_features=3, noise=10, random_state=42)\n",
    "\n",
    "print(\"\\n\\nREGRESSION: Predicting numbers\")\n",
    "print(f\"Target values (first 10): {y_reg[:10].round(2)}\")\n",
    "print(f\"Range: {y_reg.min():.2f} to {y_reg.max():.2f}\")\n",
    "print(\"Example: Predicting house prices ($100,000 to $500,000)\")\n",
    "\n",
    "print(\"\\n‚úÖ Classification ‚Üí Categories (0, 1, 2)\")\n",
    "print(\"‚úÖ Regression ‚Üí Continuous numbers (123.45, -67.89)\")\n",
    "\n",
    "# ============================================================================\n",
    "# PRACTICE 3: Train/Test Split\n",
    "# ============================================================================\n",
    "print(\"\\n\\nüìå PRACTICE 3: Train/Test Split\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Create sample data\n",
    "X = np.random.rand(100, 4)  # 100 samples, 4 features\n",
    "y = np.random.randint(0, 2, 100)  # Binary classification\n",
    "\n",
    "# Split 80/20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                     random_state=42)\n",
    "\n",
    "print(f\"Original data: {X.shape[0]} samples\")\n",
    "print(f\"\\nAfter split:\")\n",
    "print(f\"  X_train shape: {X_train.shape} (80% = {X_train.shape[0]} samples)\")\n",
    "print(f\"  X_test shape:  {X_test.shape} (20% = {X_test.shape[0]} samples)\")\n",
    "print(f\"  y_train shape: {y_train.shape}\")\n",
    "print(f\"  y_test shape:  {y_test.shape}\")\n",
    "print(f\"\\n‚úÖ Train on 80%, Test on 20% (never test on training data!)\")\n",
    "\n",
    "# Test reproducibility\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=0.2, \n",
    "                                                         random_state=42)\n",
    "print(f\"\\nWith same random_state=42:\")\n",
    "print(f\"  Are splits identical? {np.array_equal(X_train, X_train2)}\")\n",
    "\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X, y, test_size=0.2, \n",
    "                                                         random_state=99)\n",
    "print(f\"\\nWith different random_state=99:\")\n",
    "print(f\"  Are splits identical? {np.array_equal(X_train, X_train3)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PRACTICE 4: Data Scaling with StandardScaler\n",
    "# ============================================================================\n",
    "print(\"\\n\\nüìå PRACTICE 4: Data Scaling with StandardScaler\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Create data with different scales\n",
    "data_unscaled = np.array([\n",
    "    [1, 1000, 0.5],      # Feature 1: 0-10, Feature 2: 1000-10000, Feature 3: 0-1\n",
    "    [5, 5000, 0.7],\n",
    "    [10, 10000, 0.9]\n",
    "])\n",
    "\n",
    "print(\"BEFORE scaling:\")\n",
    "print(data_unscaled)\n",
    "print(f\"\\nFeature 1 range: {data_unscaled[:, 0].min()} to {data_unscaled[:, 0].max()}\")\n",
    "print(f\"Feature 2 range: {data_unscaled[:, 1].min()} to {data_unscaled[:, 1].max()}\")\n",
    "print(f\"Feature 3 range: {data_unscaled[:, 2].min():.1f} to {data_unscaled[:, 2].max():.1f}\")\n",
    "\n",
    "# Scale\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data_unscaled)\n",
    "\n",
    "print(\"\\n\\nAFTER StandardScaler:\")\n",
    "print(data_scaled.round(3))\n",
    "print(f\"\\nAll features now have:\")\n",
    "print(f\"  Mean ‚âà 0: {data_scaled.mean(axis=0).round(10)}\")\n",
    "print(f\"  Std ‚âà 1:  {data_scaled.std(axis=0).round(3)}\")\n",
    "print(\"\\n‚úÖ StandardScaler: (x - mean) / std ‚Üí Mean=0, Std=1\")\n",
    "\n",
    "# ============================================================================\n",
    "# PRACTICE 5: fit_transform vs transform\n",
    "# ============================================================================\n",
    "print(\"\\n\\nüìå PRACTICE 5: fit_transform vs transform (CRITICAL!)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Simulate train/test split\n",
    "X_train = np.array([[1], [2], [3], [4], [5]])\n",
    "X_test = np.array([[6], [7]])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# CORRECT: fit_transform on train, transform on test\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"CORRECT approach:\")\n",
    "print(f\"X_train (original): {X_train.ravel()}\")\n",
    "print(f\"X_train (scaled):   {X_train_scaled.ravel().round(3)}\")\n",
    "print(f\"  ‚Üí fit_transform() learns mean={scaler.mean_[0]:.1f}, std={scaler.scale_[0]:.2f}\")\n",
    "\n",
    "print(f\"\\nX_test (original): {X_test.ravel()}\")\n",
    "print(f\"X_test (scaled):   {X_test_scaled.ravel().round(3)}\")\n",
    "print(f\"  ‚Üí transform() uses training mean={scaler.mean_[0]:.1f}, std={scaler.scale_[0]:.2f}\")\n",
    "\n",
    "# WRONG: fit_transform on test\n",
    "scaler_wrong = StandardScaler()\n",
    "X_test_wrong = scaler_wrong.fit_transform(X_test)\n",
    "print(f\"\\n\\n‚ùå WRONG: fit_transform on test\")\n",
    "print(f\"X_test (scaled wrong): {X_test_wrong.ravel().round(3)}\")\n",
    "print(f\"  ‚Üí Uses test mean={scaler_wrong.mean_[0]:.1f}, std={scaler_wrong.scale_[0]:.2f}\")\n",
    "print(f\"  ‚Üí This is DATA LEAKAGE! Never fit on test data!\")\n",
    "\n",
    "print(\"\\n\\n‚úÖ RULE: fit_transform(train), transform(test)\")\n",
    "\n",
    "# ============================================================================\n",
    "# PRACTICE 6: The scikit-learn API - fit, predict, score\n",
    "# ============================================================================\n",
    "print(\"\\n\\nüìå PRACTICE 6: scikit-learn API - fit, predict, score\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Create simple classification data\n",
    "X_simple = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7]])\n",
    "y_simple = np.array([0, 0, 0, 1, 1, 1])\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_simple, y_simple, \n",
    "                                                     test_size=0.33, random_state=42)\n",
    "\n",
    "# Step 1: Create model\n",
    "model = LogisticRegression()\n",
    "print(\"Step 1: CREATE model\")\n",
    "print(f\"  model = LogisticRegression()\")\n",
    "\n",
    "# Step 2: Train model\n",
    "print(\"\\nStep 2: TRAIN model (fit)\")\n",
    "model.fit(X_train, y_train)\n",
    "print(f\"  model.fit(X_train, y_train)\")\n",
    "print(f\"  ‚Üí Model learned from {X_train.shape[0]} training samples\")\n",
    "\n",
    "# Step 3: Make predictions\n",
    "print(\"\\nStep 3: PREDICT on new data\")\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"  y_pred = model.predict(X_test)\")\n",
    "print(f\"  ‚Üí Predictions: {y_pred}\")\n",
    "print(f\"  ‚Üí Actual:      {y_test}\")\n",
    "\n",
    "# Step 4: Evaluate\n",
    "print(\"\\nStep 4: EVALUATE model (score)\")\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f\"  accuracy = model.score(X_test, y_test)\")\n",
    "print(f\"  ‚Üí Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "print(\"\\n‚úÖ All scikit-learn models: CREATE ‚Üí FIT ‚Üí PREDICT ‚Üí SCORE\")\n",
    "\n",
    "# ============================================================================\n",
    "# PRACTICE 7: Classification Metrics\n",
    "# ============================================================================\n",
    "print(\"\\n\\nüìå PRACTICE 7: Classification Metrics\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Simulate predictions\n",
    "y_true = np.array([0, 0, 1, 1, 1, 0, 1, 0, 1, 1])\n",
    "y_pred = np.array([0, 0, 1, 1, 0, 0, 1, 1, 1, 1])\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(\"True labels:      \", y_true)\n",
    "print(\"Predicted labels: \", y_pred)\n",
    "print(f\"\\nAccuracy: {accuracy:.2%}\")\n",
    "print(f\"  ‚Üí {int(accuracy*10)} out of 10 predictions correct\")\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"        Predicted\")\n",
    "print(\"           0  1\")\n",
    "print(f\"Actual 0  {conf_matrix[0,0]}  {conf_matrix[0,1]}\")\n",
    "print(f\"       1  {conf_matrix[1,0]}  {conf_matrix[1,1]}\")\n",
    "\n",
    "print(\"\\n‚úÖ Accuracy = (Correct predictions) / (Total predictions)\")\n",
    "\n",
    "# ============================================================================\n",
    "# PRACTICE 8: Regression Metrics\n",
    "# ============================================================================\n",
    "print(\"\\n\\nüìå PRACTICE 8: Regression Metrics\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Simulate predictions\n",
    "y_true = np.array([100, 200, 300, 400, 500])\n",
    "y_pred = np.array([110, 190, 310, 390, 510])\n",
    "\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(\"True values:      \", y_true)\n",
    "print(\"Predicted values: \", y_pred)\n",
    "print(\"Errors:           \", y_pred - y_true)\n",
    "\n",
    "print(f\"\\nMean Squared Error (MSE):  {mse:.2f}\")\n",
    "print(f\"Root MSE (RMSE):           {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"R¬≤ Score:                  {r2:.4f}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Lower MSE/RMSE/MAE = Better\")\n",
    "print(f\"‚úÖ Higher R¬≤ (max=1.0) = Better\")\n",
    "\n",
    "# ============================================================================\n",
    "# PRACTICE 9: Cross-Validation\n",
    "# ============================================================================\n",
    "print(\"\\n\\nüìå PRACTICE 9: Cross-Validation\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Create data\n",
    "X, y = make_classification(n_samples=100, n_features=10, random_state=42)\n",
    "\n",
    "# Single train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "single_score = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Single train/test split accuracy: {single_score:.3f}\")\n",
    "print(\"  ‚Üí Result depends on which data ended up in train vs test\")\n",
    "\n",
    "# 5-fold cross-validation\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "print(f\"\\n5-Fold Cross-Validation scores: {scores.round(3)}\")\n",
    "print(f\"Average accuracy: {scores.mean():.3f} (+/- {scores.std():.3f})\")\n",
    "print(\"  ‚Üí More reliable estimate, uses all data for both train and test\")\n",
    "\n",
    "print(\"\\n‚úÖ Cross-validation gives more robust performance estimate\")\n",
    "\n",
    "# ============================================================================\n",
    "# SUMMARY\n",
    "# ============================================================================\n",
    "print(\"\\n\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ PRACTICE COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nüéØ You've practiced:\")\n",
    "print(\"  1. Features (X) and Target (y)\")\n",
    "print(\"  2. Classification vs Regression\")\n",
    "print(\"  3. Train/test split with train_test_split()\")\n",
    "print(\"  4. Data scaling with StandardScaler()\")\n",
    "print(\"  5. fit_transform() vs transform()\")\n",
    "print(\"  6. scikit-learn API: fit(), predict(), score()\")\n",
    "print(\"  7. Classification metrics (accuracy, confusion matrix)\")\n",
    "print(\"  8. Regression metrics (MSE, RMSE, MAE, R¬≤)\")\n",
    "print(\"  9. Cross-validation with cross_val_score()\")\n",
    "print(\"\\nüìö Now you're ready to build ML models on REAL datasets!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0c7675",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"intro\"></a>\n",
    "## **1. Introduction to scikit-learn**\n",
    "\n",
    "**What is scikit-learn?**\n",
    "- **The** machine learning library for Python (since 2007)\n",
    "- Built on NumPy, SciPy, and matplotlib\n",
    "- Provides simple, efficient tools for data mining and analysis\n",
    "- Open-source and commercially usable (BSD license)\n",
    "\n",
    "**Why scikit-learn?**\n",
    "- ‚úÖ **Consistent API** - All models use same `.fit()`, `.predict()` pattern\n",
    "- ‚úÖ **Comprehensive** - Classification, regression, clustering, dimensionality reduction\n",
    "- ‚úÖ **Well-documented** - Excellent tutorials and examples\n",
    "- ‚úÖ **Production-ready** - Used in industry worldwide\n",
    "\n",
    "**The scikit-learn Workflow:**\n",
    "```\n",
    "1. Load Data ‚Üí 2. Split (train/test) ‚Üí 3. Preprocess (scale, encode)\n",
    "   ‚Üì\n",
    "4. Choose Model ‚Üí 5. Train (.fit) ‚Üí 6. Predict ‚Üí 7. Evaluate\n",
    "```\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Features (X)**: Input variables (sepal length, petal width, etc.)\n",
    "- **Target (y)**: Output variable we want to predict (species, price)\n",
    "- **Training**: Model learns patterns from training data\n",
    "- **Testing**: Model evaluated on unseen test data\n",
    "- **Overfitting**: Model memorizes training data, fails on new data\n",
    "- **Underfitting**: Model too simple, can't capture patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad16cf12",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"loading\"></a>\n",
    "## **2. Loading 3 Machine Learning Datasets**\n",
    "\n",
    "We'll practice on 3 classic datasets:\n",
    "1. **Iris** - Simple 3-class classification (flowers)\n",
    "2. **Wine** - Multi-feature classification (wine types)\n",
    "3. **California Housing** - Regression (predicting house prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143ad1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING 3 MACHINE LEARNING DATASETS\n",
      "======================================================================\n",
      "\n",
      "1Ô∏è‚É£ DATASET 1: Iris Flowers (Classification)\n",
      "----------------------------------------------------------------------\n",
      "Shape: (150, 4)\n",
      "Features: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "Target classes: ['setosa' 'versicolor' 'virginica']\n",
      "Class distribution:\n",
      "0    50\n",
      "1    50\n",
      "2    50\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First 3 samples:\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "\n",
      "  species  \n",
      "0  setosa  \n",
      "1  setosa  \n",
      "2  setosa  \n",
      "\n",
      "\n",
      "2Ô∏è‚É£ DATASET 2: Wine Quality (Classification)\n",
      "----------------------------------------------------------------------\n",
      "Shape: (178, 13)\n",
      "Number of features: 13\n",
      "Target classes: ['class_0' 'class_1' 'class_2']\n",
      "Class distribution:\n",
      "0    59\n",
      "1    71\n",
      "2    48\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First 3 features:\n",
      "['alcohol', 'malic_acid', 'ash']\n",
      "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
      "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
      "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
      "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
      "\n",
      "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
      "0        3.06                  0.28             2.29             5.64  1.04   \n",
      "1        2.76                  0.26             1.28             4.38  1.05   \n",
      "2        3.24                  0.30             2.81             5.68  1.03   \n",
      "\n",
      "   od280/od315_of_diluted_wines  proline wine_class  \n",
      "0                          3.92   1065.0    class_0  \n",
      "1                          3.40   1050.0    class_0  \n",
      "2                          3.17   1185.0    class_0  \n",
      "\n",
      "\n",
      "3Ô∏è‚É£ DATASET 3: California Housing (Regression)\n",
      "----------------------------------------------------------------------\n",
      "Shape: (20640, 8)\n",
      "Features: ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
      "Target: House price (in $100,000s)\n",
      "Price range: $0.15 - $5.00 (hundreds of thousands)\n",
      "Mean price: $2.07 (= $206856)\n",
      "\n",
      "First 3 samples:\n",
      "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
      "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
      "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
      "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
      "\n",
      "   Longitude  price  \n",
      "0    -122.23  4.526  \n",
      "1    -122.22  3.585  \n",
      "2    -122.24  3.521  \n",
      "\n",
      "‚úÖ All 3 datasets loaded successfully!\n",
      "Total samples: 20,968\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"LOADING 3 MACHINE LEARNING DATASETS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ============================================================================\n",
    "# DATASET 1: Iris Flowers - Classification\n",
    "# ============================================================================\n",
    "print(\"\\n1Ô∏è‚É£ DATASET 1: Iris Flowers (Classification)\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Load iris dataset\n",
    "# Returns a Bunch object (dictionary-like structure)\n",
    "iris = load_iris()\n",
    "\n",
    "# Extract features (X) and target (y)\n",
    "X_iris = iris.data  # Feature matrix: shape (150, 4)\n",
    "y_iris = iris.target  # Target vector: shape (150,)\n",
    "\n",
    "# Convert to DataFrame for easier viewing\n",
    "iris_df = pd.DataFrame(X_iris, columns=iris.feature_names)\n",
    "iris_df['species'] = iris.target_names[y_iris]  # Map 0,1,2 to species names\n",
    "\n",
    "print(f\"Shape: {X_iris.shape}\")  # (samples, features)\n",
    "print(f\"Features: {iris.feature_names}\")\n",
    "print(f\"Target classes: {iris.target_names}\")\n",
    "print(f\"Class distribution:\")\n",
    "print(pd.Series(y_iris).value_counts().sort_index())\n",
    "print(\"\\nFirst 3 samples:\")\n",
    "print(iris_df.head(3))\n",
    "\n",
    "# ============================================================================\n",
    "# DATASET 2: Wine - Classification  \n",
    "# ============================================================================\n",
    "print(\"\\n\\n2Ô∏è‚É£ DATASET 2: Wine Quality (Classification)\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Load wine dataset\n",
    "wine = load_wine()\n",
    "\n",
    "X_wine = wine.data  # Features: shape (178, 13)\n",
    "y_wine = wine.target  # Target: shape (178,)\n",
    "\n",
    "wine_df = pd.DataFrame(X_wine, columns=wine.feature_names)\n",
    "wine_df['wine_class'] = wine.target_names[y_wine]\n",
    "\n",
    "print(f\"Shape: {X_wine.shape}\")\n",
    "print(f\"Number of features: {X_wine.shape[1]}\")\n",
    "print(f\"Target classes: {wine.target_names}\")\n",
    "print(f\"Class distribution:\")\n",
    "print(pd.Series(y_wine).value_counts().sort_index())\n",
    "print(\"\\nFirst 3 features:\")\n",
    "print(wine.feature_names[:3])\n",
    "print(wine_df.head(3))\n",
    "\n",
    "# ============================================================================\n",
    "# DATASET 3: California Housing - Regression\n",
    "# ============================================================================\n",
    "print(\"\\n\\n3Ô∏è‚É£ DATASET 3: California Housing (Regression)\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Load housing dataset\n",
    "# This downloads data from internet on first run\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_housing = housing.data  # Features: shape (20640, 8)\n",
    "y_housing = housing.target  # Target (house prices in $100,000s)\n",
    "\n",
    "housing_df = pd.DataFrame(X_housing, columns=housing.feature_names)\n",
    "housing_df['price'] = y_housing\n",
    "\n",
    "print(f\"Shape: {X_housing.shape}\")\n",
    "print(f\"Features: {housing.feature_names}\")\n",
    "print(f\"Target: House price (in $100,000s)\")\n",
    "print(f\"Price range: ${y_housing.min():.2f} - ${y_housing.max():.2f} (hundreds of thousands)\")\n",
    "print(f\"Mean price: ${y_housing.mean():.2f} (= ${y_housing.mean()*100000:.0f})\")\n",
    "print(\"\\nFirst 3 samples:\")\n",
    "print(housing_df.head(3))\n",
    "\n",
    "print(\"\\n‚úÖ All 3 datasets loaded successfully!\")\n",
    "print(f\"Total samples: {len(X_iris) + len(X_wine) + len(X_housing):,}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e49cef",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"split\"></a>\n",
    "## **3. Train/Test Split - The Foundation**\n",
    "\n",
    "**Why Split Data?**\n",
    "- **Training set**: Model learns patterns from this data\n",
    "- **Test set**: Evaluate model on unseen data (simulates real-world performance)\n",
    "- **Rule of thumb**: 70-80% train, 20-30% test\n",
    "\n",
    "**Key Parameters:**\n",
    "- `test_size=0.2` - Use 20% for testing\n",
    "- `random_state=42` - Makes split reproducible\n",
    "- `stratify=y` - Keeps class balance in splits\n",
    "\n",
    "**Critical Rule:** NEVER let model see test data during training!\n",
    "\n",
    "---\n",
    "\n",
    "<a id=\"preprocessing\"></a>\n",
    "## **4. Data Preprocessing - Preparing for ML**\n",
    "\n",
    "**Why Preprocess?**\n",
    "- Different features have different scales (age: 0-100, income: 0-1000000)\n",
    "- ML algorithms perform better with normalized data\n",
    "- Some algorithms (KNN, SVM) require scaling\n",
    "\n",
    "**Common Preprocessing:**\n",
    "1. **StandardScaler**: Mean=0, StdDev=1 (most common)\n",
    "2. **MinMaxScaler**: Scale to range [0, 1]\n",
    "3. **Label Encoding**: Convert categories to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca4a82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TRAIN/TEST SPLIT & PREPROCESSING\n",
      "======================================================================\n",
      "\n",
      "1Ô∏è‚É£ SPLITTING DATA INTO TRAIN AND TEST SETS\n",
      "----------------------------------------------------------------------\n",
      "üå∏ IRIS:\n",
      "  Total samples: 150\n",
      "  Training set: 120 samples (80%)\n",
      "  Test set: 30 samples (20%)\n",
      "  Features shape: (120, 4)\n",
      "  Train class distribution: [40 40 40]\n",
      "  Test class distribution: [10 10 10]\n",
      "\n",
      "üç∑ WINE:\n",
      "  Total samples: 178\n",
      "  Training set: 142 samples\n",
      "  Test set: 36 samples\n",
      "  Train class distribution: [47 57 38]\n",
      "\n",
      "üè† HOUSING:\n",
      "  Total samples: 20,640\n",
      "  Training set: 16,512 samples\n",
      "  Test set: 4,128 samples\n",
      "  Train price mean: $2.07 (hundreds of thousands)\n",
      "\n",
      "\n",
      "2Ô∏è‚É£ FEATURE SCALING WITH STANDARDSCALER\n",
      "----------------------------------------------------------------------\n",
      "BEFORE SCALING - Iris feature ranges:\n",
      "  Sepal length: 4.30 to 7.90\n",
      "  Sepal width:  2.00 to 4.40\n",
      "  Petal length: 1.10 to 6.90\n",
      "  Petal width:  0.10 to 2.50\n",
      "\n",
      "AFTER SCALING - Iris (mean‚âà0, std‚âà1):\n",
      "  Feature 0 - Mean: -0.000000, Std: 1.000000\n",
      "  Feature 1 - Mean: -0.000000, Std: 1.000000\n",
      "\n",
      "üç∑ WINE scaled:\n",
      "  Original feature 0 range: 11.03 to 14.83\n",
      "  Scaled feature 0 range: -2.43 to 2.32\n",
      "\n",
      "üè† HOUSING scaled:\n",
      "  Before: Feature means range from -119.58 to 1426.45\n",
      "  After:  All features have mean ‚âà 0, std ‚âà 1\n",
      "\n",
      "\n",
      "3Ô∏è‚É£ VISUALIZING IMPACT OF SCALING\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scaling makes features comparable!\n",
      "‚úÖ Most ML algorithms perform better with scaled data\n",
      "\n",
      "\n",
      "4Ô∏è‚É£ CRITICAL: AVOIDING DATA LEAKAGE\n",
      "----------------------------------------------------------------------\n",
      "‚ùå WRONG WAY (causes data leakage):\n",
      "  scaler.fit(entire_dataset)  # DON'T DO THIS!\n",
      "  X_train_scaled = scaler.transform(X_train)\n",
      "  X_test_scaled = scaler.transform(X_test)\n",
      "\n",
      "  Problem: Test set statistics leaked into training!\n",
      "\n",
      "‚úÖ CORRECT WAY:\n",
      "  scaler.fit(X_train)  # Fit ONLY on training data\n",
      "  X_train_scaled = scaler.transform(X_train)\n",
      "  X_test_scaled = scaler.transform(X_test)  # Use training statistics\n",
      "\n",
      "  Result: Test set remains truly unseen!\n",
      "\n",
      "‚úÖ Train/test split and preprocessing completed for all 3 datasets!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"TRAIN/TEST SPLIT & PREPROCESSING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ============================================================================\n",
    "# PART 1: Train/Test Split for All 3 Datasets\n",
    "# ============================================================================\n",
    "print(\"\\n1Ô∏è‚É£ SPLITTING DATA INTO TRAIN AND TEST SETS\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Split Iris dataset\n",
    "# train_test_split(X, y, test_size, random_state, stratify)\n",
    "# stratify=y ensures each split has same class proportions\n",
    "X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(\n",
    "    X_iris, y_iris,\n",
    "    test_size=0.2,      # 20% for testing, 80% for training\n",
    "    random_state=42,    # For reproducibility\n",
    "    stratify=y_iris     # Keep class balance\n",
    ")\n",
    "\n",
    "print(\"üå∏ IRIS:\")\n",
    "print(f\"  Total samples: {len(X_iris)}\")\n",
    "print(f\"  Training set: {len(X_train_iris)} samples ({len(X_train_iris)/len(X_iris)*100:.0f}%)\")\n",
    "print(f\"  Test set: {len(X_test_iris)} samples ({len(X_test_iris)/len(X_iris)*100:.0f}%)\")\n",
    "print(f\"  Features shape: {X_train_iris.shape}\")\n",
    "print(f\"  Train class distribution: {np.bincount(y_train_iris)}\")\n",
    "print(f\"  Test class distribution: {np.bincount(y_test_iris)}\")\n",
    "\n",
    "# Split Wine dataset\n",
    "X_train_wine, X_test_wine, y_train_wine, y_test_wine = train_test_split(\n",
    "    X_wine, y_wine,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_wine\n",
    ")\n",
    "\n",
    "print(\"\\nüç∑ WINE:\")\n",
    "print(f\"  Total samples: {len(X_wine)}\")\n",
    "print(f\"  Training set: {len(X_train_wine)} samples\")\n",
    "print(f\"  Test set: {len(X_test_wine)} samples\")\n",
    "print(f\"  Train class distribution: {np.bincount(y_train_wine)}\")\n",
    "\n",
    "# Split Housing dataset (no stratify for regression)\n",
    "X_train_housing, X_test_housing, y_train_housing, y_test_housing = train_test_split(\n",
    "    X_housing, y_housing,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    "    # No stratify for regression (only for classification)\n",
    ")\n",
    "\n",
    "print(\"\\nüè† HOUSING:\")\n",
    "print(f\"  Total samples: {len(X_housing):,}\")\n",
    "print(f\"  Training set: {len(X_train_housing):,} samples\")\n",
    "print(f\"  Test set: {len(X_test_housing):,} samples\")\n",
    "print(f\"  Train price mean: ${y_train_housing.mean():.2f} (hundreds of thousands)\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 2: Feature Scaling - StandardScaler\n",
    "# ============================================================================\n",
    "print(\"\\n\\n2Ô∏è‚É£ FEATURE SCALING WITH STANDARDSCALER\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Demonstrate need for scaling\n",
    "print(\"BEFORE SCALING - Iris feature ranges:\")\n",
    "print(f\"  Sepal length: {X_train_iris[:, 0].min():.2f} to {X_train_iris[:, 0].max():.2f}\")\n",
    "print(f\"  Sepal width:  {X_train_iris[:, 1].min():.2f} to {X_train_iris[:, 1].max():.2f}\")\n",
    "print(f\"  Petal length: {X_train_iris[:, 2].min():.2f} to {X_train_iris[:, 2].max():.2f}\")\n",
    "print(f\"  Petal width:  {X_train_iris[:, 3].min():.2f} to {X_train_iris[:, 3].max():.2f}\")\n",
    "\n",
    "# Create scaler for Iris\n",
    "scaler_iris = StandardScaler()\n",
    "\n",
    "# IMPORTANT: Fit scaler ONLY on training data\n",
    "# This prevents data leakage from test set\n",
    "scaler_iris.fit(X_train_iris)\n",
    "\n",
    "# Transform both train and test using training statistics\n",
    "X_train_iris_scaled = scaler_iris.transform(X_train_iris)\n",
    "X_test_iris_scaled = scaler_iris.transform(X_test_iris)\n",
    "\n",
    "print(\"\\nAFTER SCALING - Iris (mean‚âà0, std‚âà1):\")\n",
    "print(f\"  Feature 0 - Mean: {X_train_iris_scaled[:, 0].mean():.6f}, Std: {X_train_iris_scaled[:, 0].std():.6f}\")\n",
    "print(f\"  Feature 1 - Mean: {X_train_iris_scaled[:, 1].mean():.6f}, Std: {X_train_iris_scaled[:, 1].std():.6f}\")\n",
    "\n",
    "# Scale Wine dataset\n",
    "scaler_wine = StandardScaler()\n",
    "X_train_wine_scaled = scaler_wine.fit_transform(X_train_wine)  # fit + transform in one step\n",
    "X_test_wine_scaled = scaler_wine.transform(X_test_wine)\n",
    "\n",
    "print(\"\\nüç∑ WINE scaled:\")\n",
    "print(f\"  Original feature 0 range: {X_train_wine[:, 0].min():.2f} to {X_train_wine[:, 0].max():.2f}\")\n",
    "print(f\"  Scaled feature 0 range: {X_train_wine_scaled[:, 0].min():.2f} to {X_train_wine_scaled[:, 0].max():.2f}\")\n",
    "\n",
    "# Scale Housing dataset\n",
    "scaler_housing = StandardScaler()\n",
    "X_train_housing_scaled = scaler_housing.fit_transform(X_train_housing)\n",
    "X_test_housing_scaled = scaler_housing.transform(X_test_housing)\n",
    "\n",
    "print(\"\\nüè† HOUSING scaled:\")\n",
    "print(f\"  Before: Feature means range from {X_train_housing.mean(axis=0).min():.2f} to {X_train_housing.mean(axis=0).max():.2f}\")\n",
    "print(f\"  After:  All features have mean ‚âà 0, std ‚âà 1\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 3: Why Scaling Matters - Visualization\n",
    "# ============================================================================\n",
    "print(\"\\n\\n3Ô∏è‚É£ VISUALIZING IMPACT OF SCALING\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Before scaling\n",
    "ax = axes[0]\n",
    "ax.scatter(X_train_iris[:, 2], X_train_iris[:, 3], \n",
    "          c=y_train_iris, cmap='viridis', alpha=0.6, s=50)\n",
    "ax.set_xlabel('Petal Length (cm)', fontsize=11)\n",
    "ax.set_ylabel('Petal Width (cm)', fontsize=11)\n",
    "ax.set_title('BEFORE Scaling - Different Scales', fontsize=12, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# After scaling\n",
    "ax = axes[1]\n",
    "ax.scatter(X_train_iris_scaled[:, 2], X_train_iris_scaled[:, 3], \n",
    "          c=y_train_iris, cmap='viridis', alpha=0.6, s=50)\n",
    "ax.set_xlabel('Petal Length (scaled)', fontsize=11)\n",
    "ax.set_ylabel('Petal Width (scaled)', fontsize=11)\n",
    "ax.set_title('AFTER Scaling - Normalized', fontsize=12, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Scaling makes features comparable!\")\n",
    "print(\"‚úÖ Most ML algorithms perform better with scaled data\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 4: Data Leakage Warning\n",
    "# ============================================================================\n",
    "print(\"\\n\\n4Ô∏è‚É£ CRITICAL: AVOIDING DATA LEAKAGE\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "print(\"‚ùå WRONG WAY (causes data leakage):\")\n",
    "print(\"  scaler.fit(entire_dataset)  # DON'T DO THIS!\")\n",
    "print(\"  X_train_scaled = scaler.transform(X_train)\")\n",
    "print(\"  X_test_scaled = scaler.transform(X_test)\")\n",
    "print(\"\\n  Problem: Test set statistics leaked into training!\")\n",
    "\n",
    "print(\"\\n‚úÖ CORRECT WAY:\")\n",
    "print(\"  scaler.fit(X_train)  # Fit ONLY on training data\")\n",
    "print(\"  X_train_scaled = scaler.transform(X_train)\")\n",
    "print(\"  X_test_scaled = scaler.transform(X_test)  # Use training statistics\")\n",
    "print(\"\\n  Result: Test set remains truly unseen!\")\n",
    "\n",
    "print(\"\\n‚úÖ Train/test split and preprocessing completed for all 3 datasets!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d20033",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **5. Classification Models - Predicting Categories**\n",
    "\n",
    "**What is Classification?**\n",
    "- Predicting which category (class) something belongs to\n",
    "- Output: Discrete labels (0, 1, 2 or \"setosa\", \"versicolor\", \"virginica\")\n",
    "- Examples: Email spam detection, disease diagnosis, species identification\n",
    "\n",
    "**Models We'll Use:**\n",
    "1. **Logistic Regression** - Simple, interpretable, great baseline\n",
    "2. **Random Forest** - Ensemble of decision trees, handles non-linear patterns\n",
    "\n",
    "**Datasets:**\n",
    "- üå∏ **Iris**: 3 flower species based on 4 measurements\n",
    "- üç∑ **Wine**: 3 wine types based on 13 chemical properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf277606",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"CLASSIFICATION MODELS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ============================================================================\n",
    "# PART 1: Logistic Regression on Iris Dataset\n",
    "# ============================================================================\n",
    "print(\"\\n1Ô∏è‚É£ LOGISTIC REGRESSION ON IRIS\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Create logistic regression model\n",
    "# LogisticRegression is a LINEAR classifier despite the name\n",
    "# It works well for linearly separable classes\n",
    "lr_iris = LogisticRegression(\n",
    "    max_iter=200,      # Maximum iterations for convergence\n",
    "    random_state=42    # For reproducibility\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "# .fit() learns the decision boundaries from training data\n",
    "print(\"Training Logistic Regression on Iris (120 samples)...\")\n",
    "lr_iris.fit(X_train_iris_scaled, y_train_iris)\n",
    "\n",
    "# Make predictions on test set\n",
    "# .predict() returns predicted class labels\n",
    "y_pred_iris_lr = lr_iris.predict(X_test_iris_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "# accuracy = (correct predictions) / (total predictions)\n",
    "accuracy_iris_lr = accuracy_score(y_test_iris, y_pred_iris_lr)\n",
    "\n",
    "print(f\"\\n‚úÖ Model trained successfully!\")\n",
    "print(f\"üìä Test Accuracy: {accuracy_iris_lr:.2%}\")\n",
    "print(f\"   Got {int(accuracy_iris_lr * len(y_test_iris))} out of {len(y_test_iris)} correct\")\n",
    "\n",
    "# Show some predictions vs actual\n",
    "print(\"\\nüîç Sample Predictions (first 10):\")\n",
    "print(f\"   Predicted: {y_pred_iris_lr[:10]}\")\n",
    "print(f\"   Actual:    {y_test_iris[:10]}\")\n",
    "print(f\"   Match:     {y_pred_iris_lr[:10] == y_test_iris[:10]}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "# Shows where model gets confused between classes\n",
    "cm_iris_lr = confusion_matrix(y_test_iris, y_pred_iris_lr)\n",
    "print(\"\\nüìã Confusion Matrix:\")\n",
    "print(\"   Rows = Actual, Columns = Predicted\")\n",
    "print(cm_iris_lr)\n",
    "\n",
    "# Classification Report\n",
    "# Precision, Recall, F1-score for each class\n",
    "print(\"\\nüìà Classification Report:\")\n",
    "print(classification_report(y_test_iris, y_pred_iris_lr, \n",
    "                          target_names=['Setosa', 'Versicolor', 'Virginica']))\n",
    "\n",
    "# ============================================================================\n",
    "# PART 2: Random Forest on Iris Dataset\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"2Ô∏è‚É£ RANDOM FOREST ON IRIS\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Create Random Forest classifier\n",
    "# Ensemble of 100 decision trees voting together\n",
    "rf_iris = RandomForestClassifier(\n",
    "    n_estimators=100,   # Number of trees in the forest\n",
    "    max_depth=5,        # Maximum depth of each tree\n",
    "    random_state=42     # For reproducibility\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"Training Random Forest (100 trees) on Iris...\")\n",
    "rf_iris.fit(X_train_iris_scaled, y_train_iris)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_iris_rf = rf_iris.predict(X_test_iris_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_iris_rf = accuracy_score(y_test_iris, y_pred_iris_rf)\n",
    "\n",
    "print(f\"\\n‚úÖ Model trained successfully!\")\n",
    "print(f\"üìä Test Accuracy: {accuracy_iris_rf:.2%}\")\n",
    "print(f\"   Improvement over Logistic Regression: {(accuracy_iris_rf - accuracy_iris_lr):.2%}\")\n",
    "\n",
    "# Feature Importance\n",
    "# Which features matter most for prediction?\n",
    "feature_importance_iris = rf_iris.feature_importances_\n",
    "feature_names = ['Sepal Length', 'Sepal Width', 'Petal Length', 'Petal Width']\n",
    "\n",
    "print(\"\\nüéØ Feature Importance (which features matter most?):\")\n",
    "for name, importance in zip(feature_names, feature_importance_iris):\n",
    "    print(f\"   {name:15s}: {'‚ñà' * int(importance * 50)} {importance:.3f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 3: Logistic Regression on Wine Dataset\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"3Ô∏è‚É£ LOGISTIC REGRESSION ON WINE\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Train model on wine dataset\n",
    "lr_wine = LogisticRegression(max_iter=1000, random_state=42)\n",
    "print(\"Training Logistic Regression on Wine (142 samples)...\")\n",
    "lr_wine.fit(X_train_wine_scaled, y_train_wine)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred_wine_lr = lr_wine.predict(X_test_wine_scaled)\n",
    "accuracy_wine_lr = accuracy_score(y_test_wine, y_pred_wine_lr)\n",
    "\n",
    "print(f\"\\n‚úÖ Test Accuracy: {accuracy_wine_lr:.2%}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm_wine_lr = confusion_matrix(y_test_wine, y_pred_wine_lr)\n",
    "print(\"\\nüìã Confusion Matrix:\")\n",
    "print(cm_wine_lr)\n",
    "\n",
    "# ============================================================================\n",
    "# PART 4: Random Forest on Wine Dataset\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"4Ô∏è‚É£ RANDOM FOREST ON WINE\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Train Random Forest\n",
    "rf_wine = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "print(\"Training Random Forest on Wine...\")\n",
    "rf_wine.fit(X_train_wine_scaled, y_train_wine)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred_wine_rf = rf_wine.predict(X_test_wine_scaled)\n",
    "accuracy_wine_rf = accuracy_score(y_test_wine, y_pred_wine_rf)\n",
    "\n",
    "print(f\"\\n‚úÖ Test Accuracy: {accuracy_wine_rf:.2%}\")\n",
    "\n",
    "# Top 5 most important features\n",
    "feature_importance_wine = rf_wine.feature_importances_\n",
    "top_5_indices = np.argsort(feature_importance_wine)[-5:][::-1]\n",
    "\n",
    "print(\"\\nüéØ Top 5 Most Important Features:\")\n",
    "for i, idx in enumerate(top_5_indices, 1):\n",
    "    print(f\"   {i}. Feature {idx}: {feature_importance_wine[idx]:.3f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 5: Model Comparison Visualization\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"5Ô∏è‚É£ COMPARING ALL CLASSIFICATION MODELS\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Create comparison bar chart\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Iris comparison\n",
    "ax = axes[0]\n",
    "models = ['Logistic\\nRegression', 'Random\\nForest']\n",
    "accuracies = [accuracy_iris_lr, accuracy_iris_rf]\n",
    "bars = ax.bar(models, accuracies, color=['#3498db', '#2ecc71'], alpha=0.7, edgecolor='black')\n",
    "ax.set_ylim(0.9, 1.0)\n",
    "ax.set_ylabel('Accuracy', fontsize=12)\n",
    "ax.set_title('üå∏ Iris Classification', fontsize=13, fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "# Add value labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
    "            f'{height:.2%}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "# Wine comparison\n",
    "ax = axes[1]\n",
    "accuracies = [accuracy_wine_lr, accuracy_wine_rf]\n",
    "bars = ax.bar(models, accuracies, color=['#3498db', '#2ecc71'], alpha=0.7, edgecolor='black')\n",
    "ax.set_ylim(0.9, 1.0)\n",
    "ax.set_ylabel('Accuracy', fontsize=12)\n",
    "ax.set_title('üç∑ Wine Classification', fontsize=13, fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "# Add value labels\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
    "            f'{height:.2%}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Classification models trained and evaluated!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a44fcb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **6. Regression Models - Predicting Numbers**\n",
    "\n",
    "**What is Regression?**\n",
    "- Predicting continuous numerical values\n",
    "- Output: Real numbers (house prices, temperatures, stock prices)\n",
    "- Examples: Predicting house prices, sales forecasting, temperature prediction\n",
    "\n",
    "**Models We'll Use:**\n",
    "1. **Linear Regression** - Assumes linear relationship between features and target\n",
    "2. **Random Forest Regressor** - Handles non-linear patterns, more flexible\n",
    "\n",
    "**Dataset:**\n",
    "- üè† **California Housing**: Predict median house prices based on 8 features\n",
    "  - Features: population, median income, house age, average rooms, etc.\n",
    "  - Target: Median house value (in $100,000s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecca376",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"REGRESSION MODELS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ============================================================================\n",
    "# PART 1: Linear Regression on Housing Dataset\n",
    "# ============================================================================\n",
    "print(\"\\n1Ô∏è‚É£ LINEAR REGRESSION ON CALIFORNIA HOUSING\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Create Linear Regression model\n",
    "# Fits a linear equation: y = w1*x1 + w2*x2 + ... + b\n",
    "lr_housing = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "print(f\"Training Linear Regression on {len(X_train_housing):,} houses...\")\n",
    "lr_housing.fit(X_train_housing_scaled, y_train_housing)\n",
    "\n",
    "# Make predictions on test set\n",
    "y_pred_housing_lr = lr_housing.predict(X_test_housing_scaled)\n",
    "\n",
    "# Calculate regression metrics\n",
    "# MAE = Mean Absolute Error (average difference)\n",
    "mae_lr = mean_absolute_error(y_test_housing, y_pred_housing_lr)\n",
    "# MSE = Mean Squared Error (penalizes large errors more)\n",
    "mse_lr = mean_squared_error(y_test_housing, y_pred_housing_lr)\n",
    "# RMSE = Root Mean Squared Error (same units as target)\n",
    "rmse_lr = np.sqrt(mse_lr)\n",
    "# R¬≤ = Coefficient of determination (1.0 = perfect, 0.0 = bad)\n",
    "r2_lr = r2_score(y_test_housing, y_pred_housing_lr)\n",
    "\n",
    "print(f\"\\n‚úÖ Model trained successfully!\")\n",
    "print(f\"\\nüìä Regression Metrics:\")\n",
    "print(f\"   MAE (Mean Absolute Error):  ${mae_lr:.2f} (hundred thousands)\")\n",
    "print(f\"   MSE (Mean Squared Error):   {mse_lr:.2f}\")\n",
    "print(f\"   RMSE (Root MSE):            ${rmse_lr:.2f}\")\n",
    "print(f\"   R¬≤ Score:                   {r2_lr:.4f} (closer to 1.0 is better)\")\n",
    "print(f\"\\n   üí° On average, predictions are off by ${mae_lr:.2f} √ó $100k = ${mae_lr*100:.0f}k\")\n",
    "\n",
    "# Show sample predictions\n",
    "print(\"\\nüîç Sample Predictions (first 5 houses):\")\n",
    "for i in range(5):\n",
    "    print(f\"   House {i+1}: Predicted ${y_pred_housing_lr[i]:.2f}, Actual ${y_test_housing.iloc[i]:.2f}, \"\n",
    "          f\"Diff ${abs(y_pred_housing_lr[i] - y_test_housing.iloc[i]):.2f}\")\n",
    "\n",
    "# Model coefficients\n",
    "# Each coefficient shows feature importance (how much it affects price)\n",
    "print(\"\\nüéØ Feature Coefficients (impact on price):\")\n",
    "housing_feature_names = ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', \n",
    "                         'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
    "coefficients = lr_housing.coef_\n",
    "for name, coef in sorted(zip(housing_feature_names, coefficients), \n",
    "                         key=lambda x: abs(x[1]), reverse=True)[:5]:\n",
    "    sign = \"+\" if coef > 0 else \"\"\n",
    "    print(f\"   {name:12s}: {sign}{coef:.3f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 2: Random Forest Regressor on Housing Dataset\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"2Ô∏è‚É£ RANDOM FOREST REGRESSOR ON HOUSING\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Create Random Forest Regressor\n",
    "# Ensemble of decision trees for regression\n",
    "rf_housing = RandomForestRegressor(\n",
    "    n_estimators=100,   # 100 trees\n",
    "    max_depth=20,       # Maximum depth\n",
    "    random_state=42,\n",
    "    n_jobs=-1           # Use all CPU cores for faster training\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(f\"Training Random Forest (100 trees) on {len(X_train_housing):,} houses...\")\n",
    "rf_housing.fit(X_train_housing_scaled, y_train_housing)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_housing_rf = rf_housing.predict(X_test_housing_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "mae_rf = mean_absolute_error(y_test_housing, y_pred_housing_rf)\n",
    "mse_rf = mean_squared_error(y_test_housing, y_pred_housing_rf)\n",
    "rmse_rf = np.sqrt(mse_rf)\n",
    "r2_rf = r2_score(y_test_housing, y_pred_housing_rf)\n",
    "\n",
    "print(f\"\\n‚úÖ Model trained successfully!\")\n",
    "print(f\"\\nüìä Regression Metrics:\")\n",
    "print(f\"   MAE:  ${mae_rf:.2f}\")\n",
    "print(f\"   RMSE: ${rmse_rf:.2f}\")\n",
    "print(f\"   R¬≤:   {r2_rf:.4f}\")\n",
    "print(f\"\\n   ‚ú® Improvement over Linear Regression:\")\n",
    "print(f\"      MAE improved by:  ${mae_lr - mae_rf:.2f}\")\n",
    "print(f\"      R¬≤ improved by:   {r2_rf - r2_lr:.4f}\")\n",
    "\n",
    "# Feature importance for Random Forest\n",
    "feature_importance_housing = rf_housing.feature_importances_\n",
    "\n",
    "print(\"\\nüéØ Feature Importance (what matters most for price?):\")\n",
    "importance_pairs = sorted(zip(housing_feature_names, feature_importance_housing), \n",
    "                         key=lambda x: x[1], reverse=True)\n",
    "for name, importance in importance_pairs:\n",
    "    bar = '‚ñà' * int(importance * 100)\n",
    "    print(f\"   {name:12s}: {bar} {importance:.3f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 3: Predictions vs Actual Visualization\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"3Ô∏è‚É£ VISUALIZING PREDICTIONS\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# Linear Regression: Predicted vs Actual\n",
    "ax = axes[0, 0]\n",
    "ax.scatter(y_test_housing, y_pred_housing_lr, alpha=0.3, s=20, color='blue')\n",
    "ax.plot([y_test_housing.min(), y_test_housing.max()], \n",
    "        [y_test_housing.min(), y_test_housing.max()], \n",
    "        'r--', lw=2, label='Perfect Prediction')\n",
    "ax.set_xlabel('Actual Price ($100k)', fontsize=11)\n",
    "ax.set_ylabel('Predicted Price ($100k)', fontsize=11)\n",
    "ax.set_title('Linear Regression: Predicted vs Actual', fontsize=12, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Random Forest: Predicted vs Actual\n",
    "ax = axes[0, 1]\n",
    "ax.scatter(y_test_housing, y_pred_housing_rf, alpha=0.3, s=20, color='green')\n",
    "ax.plot([y_test_housing.min(), y_test_housing.max()], \n",
    "        [y_test_housing.min(), y_test_housing.max()], \n",
    "        'r--', lw=2, label='Perfect Prediction')\n",
    "ax.set_xlabel('Actual Price ($100k)', fontsize=11)\n",
    "ax.set_ylabel('Predicted Price ($100k)', fontsize=11)\n",
    "ax.set_title('Random Forest: Predicted vs Actual', fontsize=12, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Linear Regression: Residuals (errors)\n",
    "ax = axes[1, 0]\n",
    "residuals_lr = y_test_housing - y_pred_housing_lr\n",
    "ax.scatter(y_pred_housing_lr, residuals_lr, alpha=0.3, s=20, color='blue')\n",
    "ax.axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "ax.set_xlabel('Predicted Price ($100k)', fontsize=11)\n",
    "ax.set_ylabel('Residual (Actual - Predicted)', fontsize=11)\n",
    "ax.set_title('Linear Regression: Residual Plot', fontsize=12, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Random Forest: Residuals\n",
    "ax = axes[1, 1]\n",
    "residuals_rf = y_test_housing - y_pred_housing_rf\n",
    "ax.scatter(y_pred_housing_rf, residuals_rf, alpha=0.3, s=20, color='green')\n",
    "ax.axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "ax.set_xlabel('Predicted Price ($100k)', fontsize=11)\n",
    "ax.set_ylabel('Residual (Actual - Predicted)', fontsize=11)\n",
    "ax.set_title('Random Forest: Residual Plot', fontsize=12, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# PART 4: Model Comparison\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"4Ô∏è‚É£ REGRESSION MODEL COMPARISON\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Create comparison chart\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# MAE comparison\n",
    "ax = axes[0]\n",
    "models = ['Linear\\nRegression', 'Random\\nForest']\n",
    "mae_values = [mae_lr, mae_rf]\n",
    "bars = ax.bar(models, mae_values, color=['#3498db', '#2ecc71'], alpha=0.7, edgecolor='black')\n",
    "ax.set_ylabel('MAE (Mean Absolute Error)', fontsize=12)\n",
    "ax.set_title('Lower is Better', fontsize=13, fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "            f'${height:.2f}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "# R¬≤ comparison\n",
    "ax = axes[1]\n",
    "r2_values = [r2_lr, r2_rf]\n",
    "bars = ax.bar(models, r2_values, color=['#3498db', '#2ecc71'], alpha=0.7, edgecolor='black')\n",
    "ax.set_ylabel('R¬≤ Score', fontsize=12)\n",
    "ax.set_title('Higher is Better (max 1.0)', fontsize=13, fontweight='bold')\n",
    "ax.set_ylim(0, 1)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "            f'{height:.4f}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Regression models trained and evaluated!\")\n",
    "print(f\"üèÜ Winner: Random Forest (R¬≤={r2_rf:.4f}, MAE=${mae_rf:.2f})\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c333d4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **7. Cross-Validation - Robust Model Evaluation**\n",
    "\n",
    "**Why Cross-Validation?**\n",
    "- Single train/test split might be lucky or unlucky\n",
    "- Cross-validation tests model on multiple different splits\n",
    "- More reliable estimate of true performance\n",
    "\n",
    "**K-Fold Cross-Validation:**\n",
    "1. Split data into K folds (usually 5 or 10)\n",
    "2. Train on K-1 folds, test on remaining fold\n",
    "3. Repeat K times, each fold gets to be test set once\n",
    "4. Average the K scores for final metric\n",
    "\n",
    "**Benefits:**\n",
    "- Uses all data for both training and testing\n",
    "- Reduces variance in performance estimates\n",
    "- Detects overfitting more reliably"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9424d691",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"CROSS-VALIDATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ============================================================================\n",
    "# PART 1: Cross-Validation on Iris Dataset\n",
    "# ============================================================================\n",
    "print(\"\\n1Ô∏è‚É£ 5-FOLD CROSS-VALIDATION ON IRIS\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Prepare fresh model (not trained yet)\n",
    "lr_iris_cv = LogisticRegression(max_iter=200, random_state=42)\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "# cv=5 means split data into 5 parts\n",
    "# Each part becomes test set once, others are training\n",
    "print(\"Running 5-Fold Cross-Validation...\")\n",
    "\n",
    "# Create scaled version of full dataset for CV\n",
    "scaler_iris_full = StandardScaler()\n",
    "X_iris_scaled = scaler_iris_full.fit_transform(X_iris)\n",
    "\n",
    "cv_scores_iris = cross_val_score(\n",
    "    lr_iris_cv,              # Model to evaluate\n",
    "    X_iris_scaled,           # Full feature set (scaled)\n",
    "    y_iris,                  # Full target (not split)\n",
    "    cv=5,                    # 5 folds\n",
    "    scoring='accuracy'       # Metric to compute\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Cross-Validation Scores (5 folds):\")\n",
    "for fold, score in enumerate(cv_scores_iris, 1):\n",
    "    bar = '‚ñà' * int(score * 50)\n",
    "    print(f\"   Fold {fold}: {bar} {score:.4f} ({score:.2%})\")\n",
    "\n",
    "print(f\"\\nüìà Summary Statistics:\")\n",
    "print(f\"   Mean Accuracy:  {cv_scores_iris.mean():.4f} ¬± {cv_scores_iris.std():.4f}\")\n",
    "print(f\"   Best Fold:      {cv_scores_iris.max():.4f}\")\n",
    "print(f\"   Worst Fold:     {cv_scores_iris.min():.4f}\")\n",
    "print(f\"   Range:          {cv_scores_iris.max() - cv_scores_iris.min():.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 2: Cross-Validation on Wine Dataset\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"2Ô∏è‚É£ 5-FOLD CROSS-VALIDATION ON WINE\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Random Forest on Wine\n",
    "rf_wine_cv = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "print(\"Running 5-Fold Cross-Validation on Wine...\")\n",
    "\n",
    "# Create scaled version of full dataset for CV\n",
    "scaler_wine_full = StandardScaler()\n",
    "X_wine_scaled = scaler_wine_full.fit_transform(X_wine)\n",
    "\n",
    "cv_scores_wine = cross_val_score(\n",
    "    rf_wine_cv,\n",
    "    X_wine_scaled,\n",
    "    y_wine,\n",
    "    cv=5,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Cross-Validation Scores:\")\n",
    "for fold, score in enumerate(cv_scores_wine, 1):\n",
    "    print(f\"   Fold {fold}: {score:.4f}\")\n",
    "\n",
    "print(f\"\\nüìà Mean Accuracy: {cv_scores_wine.mean():.4f} ¬± {cv_scores_wine.std():.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 3: Cross-Validation on Housing Dataset (Regression)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"3Ô∏è‚É£ 5-FOLD CROSS-VALIDATION ON HOUSING\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Random Forest Regressor with cross-validation\n",
    "rf_housing_cv = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "print(\"Running 5-Fold Cross-Validation on Housing...\")\n",
    "\n",
    "# Create scaled version of full dataset for CV\n",
    "scaler_housing_full = StandardScaler()\n",
    "X_housing_scaled = scaler_housing_full.fit_transform(X_housing)\n",
    "\n",
    "# For regression, use negative MSE (sklearn convention)\n",
    "# We negate it to get positive MSE values\n",
    "cv_scores_housing_mse = -cross_val_score(\n",
    "    rf_housing_cv,\n",
    "    X_housing_scaled,\n",
    "    y_housing,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error'  # Returns negative MSE\n",
    ")\n",
    "\n",
    "# Convert to RMSE (Root Mean Squared Error)\n",
    "cv_scores_housing_rmse = np.sqrt(cv_scores_housing_mse)\n",
    "\n",
    "print(f\"\\nüìä Cross-Validation RMSE (5 folds):\")\n",
    "for fold, rmse in enumerate(cv_scores_housing_rmse, 1):\n",
    "    print(f\"   Fold {fold}: ${rmse:.2f}\")\n",
    "\n",
    "print(f\"\\nüìà Mean RMSE: ${cv_scores_housing_rmse.mean():.2f} ¬± ${cv_scores_housing_rmse.std():.2f}\")\n",
    "\n",
    "# Also get R¬≤ scores\n",
    "cv_scores_housing_r2 = cross_val_score(\n",
    "    rf_housing_cv,\n",
    "    X_housing_scaled,\n",
    "    y_housing,\n",
    "    cv=5,\n",
    "    scoring='r2'\n",
    ")\n",
    "\n",
    "print(f\"üìà Mean R¬≤: {cv_scores_housing_r2.mean():.4f} ¬± {cv_scores_housing_r2.std():.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 4: Comparing Single Split vs Cross-Validation\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"4Ô∏è‚É£ SINGLE SPLIT VS CROSS-VALIDATION\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "print(\"\\nüîç Why Cross-Validation is Better:\")\n",
    "print(\"\\n   Single Train/Test Split:\")\n",
    "print(f\"      ‚Ä¢ One accuracy score: {accuracy_iris_lr:.4f}\")\n",
    "print(f\"      ‚Ä¢ Could be lucky or unlucky\")\n",
    "print(f\"      ‚Ä¢ No idea if result is stable\")\n",
    "\n",
    "print(\"\\n   5-Fold Cross-Validation:\")\n",
    "print(f\"      ‚Ä¢ Five accuracy scores: {cv_scores_iris}\")\n",
    "print(f\"      ‚Ä¢ Mean: {cv_scores_iris.mean():.4f}, Std: {cv_scores_iris.std():.4f}\")\n",
    "print(f\"      ‚Ä¢ More reliable estimate\")\n",
    "print(f\"      ‚Ä¢ Can see variance across folds\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 5: Visualization of Cross-Validation Results\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"5Ô∏è‚É£ VISUALIZING CROSS-VALIDATION\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Iris CV scores\n",
    "ax = axes[0]\n",
    "folds = list(range(1, 6))\n",
    "ax.plot(folds, cv_scores_iris, 'o-', linewidth=2, markersize=8, color='blue', label='Fold Scores')\n",
    "ax.axhline(cv_scores_iris.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {cv_scores_iris.mean():.3f}')\n",
    "ax.fill_between(folds, \n",
    "                cv_scores_iris.mean() - cv_scores_iris.std(),\n",
    "                cv_scores_iris.mean() + cv_scores_iris.std(),\n",
    "                alpha=0.2, color='red', label='¬±1 Std Dev')\n",
    "ax.set_xlabel('Fold Number', fontsize=11)\n",
    "ax.set_ylabel('Accuracy', fontsize=11)\n",
    "ax.set_title('üå∏ Iris: Cross-Validation Scores', fontsize=12, fontweight='bold')\n",
    "ax.set_xticks(folds)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Wine CV scores\n",
    "ax = axes[1]\n",
    "ax.plot(folds, cv_scores_wine, 'o-', linewidth=2, markersize=8, color='purple', label='Fold Scores')\n",
    "ax.axhline(cv_scores_wine.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {cv_scores_wine.mean():.3f}')\n",
    "ax.fill_between(folds,\n",
    "                cv_scores_wine.mean() - cv_scores_wine.std(),\n",
    "                cv_scores_wine.mean() + cv_scores_wine.std(),\n",
    "                alpha=0.2, color='red', label='¬±1 Std Dev')\n",
    "ax.set_xlabel('Fold Number', fontsize=11)\n",
    "ax.set_ylabel('Accuracy', fontsize=11)\n",
    "ax.set_title('üç∑ Wine: Cross-Validation Scores', fontsize=12, fontweight='bold')\n",
    "ax.set_xticks(folds)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Housing CV scores (RMSE)\n",
    "ax = axes[2]\n",
    "ax.plot(folds, cv_scores_housing_rmse, 'o-', linewidth=2, markersize=8, color='green', label='Fold RMSE')\n",
    "ax.axhline(cv_scores_housing_rmse.mean(), color='red', linestyle='--', linewidth=2, \n",
    "          label=f'Mean: ${cv_scores_housing_rmse.mean():.2f}')\n",
    "ax.fill_between(folds,\n",
    "                cv_scores_housing_rmse.mean() - cv_scores_housing_rmse.std(),\n",
    "                cv_scores_housing_rmse.mean() + cv_scores_housing_rmse.std(),\n",
    "                alpha=0.2, color='red', label='¬±1 Std Dev')\n",
    "ax.set_xlabel('Fold Number', fontsize=11)\n",
    "ax.set_ylabel('RMSE', fontsize=11)\n",
    "ax.set_title('üè† Housing: Cross-Validation RMSE', fontsize=12, fontweight='bold')\n",
    "ax.set_xticks(folds)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Cross-validation provides robust performance estimates!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14b3f9c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **8. Hyperparameter Tuning - Finding the Best Settings**\n",
    "\n",
    "**What are Hyperparameters?**\n",
    "- Settings you choose BEFORE training (not learned from data)\n",
    "- Examples: number of trees in Random Forest, learning rate, max depth\n",
    "- Different values ‚Üí different model performance\n",
    "\n",
    "**Grid Search:**\n",
    "- Try all combinations of hyperparameter values\n",
    "- Use cross-validation to evaluate each combination\n",
    "- Select the best performing combination\n",
    "\n",
    "**Example:**\n",
    "- If testing 3 values for `n_estimators` and 3 for `max_depth`\n",
    "- Grid Search tries all 3 √ó 3 = 9 combinations\n",
    "- With 5-fold CV, that's 9 √ó 5 = 45 model trainings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522468d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"HYPERPARAMETER TUNING WITH GRID SEARCH\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ============================================================================\n",
    "# PART 1: Grid Search on Iris Random Forest\n",
    "# ============================================================================\n",
    "print(\"\\n1Ô∏è‚É£ TUNING RANDOM FOREST ON IRIS\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Define hyperparameter grid to search\n",
    "# We'll test different combinations of these values\n",
    "param_grid_iris = {\n",
    "    'n_estimators': [50, 100, 200],        # Number of trees\n",
    "    'max_depth': [3, 5, 10, None],         # Maximum tree depth\n",
    "    'min_samples_split': [2, 5, 10]        # Minimum samples to split node\n",
    "}\n",
    "\n",
    "# Calculate total combinations\n",
    "total_combinations = (len(param_grid_iris['n_estimators']) * \n",
    "                     len(param_grid_iris['max_depth']) * \n",
    "                     len(param_grid_iris['min_samples_split']))\n",
    "print(f\"Testing {total_combinations} hyperparameter combinations with 5-fold CV\")\n",
    "print(f\"Total model trainings: {total_combinations * 5}\")\n",
    "\n",
    "# Create base model\n",
    "rf_base = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Create GridSearchCV object\n",
    "# This will try all combinations and find the best\n",
    "grid_search_iris = GridSearchCV(\n",
    "    estimator=rf_base,      # Model to tune\n",
    "    param_grid=param_grid_iris,  # Hyperparameters to try\n",
    "    cv=5,                   # 5-fold cross-validation\n",
    "    scoring='accuracy',     # Metric to optimize\n",
    "    n_jobs=-1,              # Use all CPU cores\n",
    "    verbose=1               # Show progress\n",
    ")\n",
    "\n",
    "# Run grid search\n",
    "print(\"\\nüîç Searching for best hyperparameters...\")\n",
    "grid_search_iris.fit(X_iris_scaled, y_iris)\n",
    "\n",
    "# Best parameters found\n",
    "print(f\"\\n‚úÖ Grid Search Complete!\")\n",
    "print(f\"\\nüèÜ Best Hyperparameters:\")\n",
    "for param, value in grid_search_iris.best_params_.items():\n",
    "    print(f\"   {param}: {value}\")\n",
    "\n",
    "print(f\"\\nüìä Best Cross-Validation Score: {grid_search_iris.best_score_:.4f}\")\n",
    "\n",
    "# Compare with default parameters\n",
    "rf_default = RandomForestClassifier(random_state=42)\n",
    "# Use unscaled data with StandardScaler transform for fair comparison\n",
    "default_scores = cross_val_score(rf_default, X_iris_scaled, y_iris, cv=5)\n",
    "print(f\"üìä Default Parameters Score:    {default_scores.mean():.4f}\")\n",
    "print(f\"\\n‚ú® Improvement: {(grid_search_iris.best_score_ - default_scores.mean()):.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 2: Grid Search on Wine Dataset\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"2Ô∏è‚É£ TUNING RANDOM FOREST ON WINE\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Smaller grid for Wine (fewer samples)\n",
    "param_grid_wine = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "print(f\"Testing {3 * 3 * 2} combinations...\")\n",
    "\n",
    "grid_search_wine = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_grid_wine,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"üîç Searching...\")\n",
    "grid_search_wine.fit(X_wine_scaled, y_wine)\n",
    "\n",
    "print(f\"\\nüèÜ Best Parameters: {grid_search_wine.best_params_}\")\n",
    "print(f\"üìä Best CV Score: {grid_search_wine.best_score_:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 3: Grid Search on Housing Dataset (Regression)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"3Ô∏è‚É£ TUNING RANDOM FOREST ON HOUSING\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Grid for regression\n",
    "param_grid_housing = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "print(f\"Testing {2 * 3 * 2} combinations...\")\n",
    "\n",
    "grid_search_housing = GridSearchCV(\n",
    "    RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "    param_grid_housing,\n",
    "    cv=3,  # Use 3 folds (dataset is large)\n",
    "    scoring='r2',  # Optimize R¬≤ score\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"üîç Searching (this may take a minute with 16k+ samples)...\")\n",
    "grid_search_housing.fit(X_housing_scaled, y_housing)\n",
    "\n",
    "print(f\"\\nüèÜ Best Parameters: {grid_search_housing.best_params_}\")\n",
    "print(f\"üìä Best CV R¬≤ Score: {grid_search_housing.best_score_:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 4: Visualizing Grid Search Results\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"4Ô∏è‚É£ ANALYZING GRID SEARCH RESULTS\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Extract results for Iris\n",
    "cv_results_iris = grid_search_iris.cv_results_\n",
    "\n",
    "# Get top 10 parameter combinations\n",
    "top_10_indices = np.argsort(cv_results_iris['mean_test_score'])[-10:][::-1]\n",
    "\n",
    "print(\"\\nüèÜ Top 10 Hyperparameter Combinations for Iris:\")\n",
    "print(\"-\" * 70)\n",
    "for rank, idx in enumerate(top_10_indices, 1):\n",
    "    params = cv_results_iris['params'][idx]\n",
    "    score = cv_results_iris['mean_test_score'][idx]\n",
    "    print(f\"{rank:2d}. Score: {score:.4f} | n_est={params['n_estimators']:3d}, \"\n",
    "          f\"depth={str(params['max_depth']):4s}, split={params['min_samples_split']:2d}\")\n",
    "\n",
    "# Visualize effect of n_estimators\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"5Ô∏è‚É£ VISUALIZING HYPERPARAMETER IMPACT\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Extract scores for different n_estimators (fixing other params)\n",
    "ax = axes[0]\n",
    "n_est_values = sorted(set([params['n_estimators'] for params in cv_results_iris['params']]))\n",
    "mean_scores_by_n_est = []\n",
    "\n",
    "for n_est in n_est_values:\n",
    "    # Get all scores with this n_estimators value\n",
    "    scores = [cv_results_iris['mean_test_score'][i] \n",
    "              for i, params in enumerate(cv_results_iris['params']) \n",
    "              if params['n_estimators'] == n_est]\n",
    "    mean_scores_by_n_est.append(np.mean(scores))\n",
    "\n",
    "ax.plot(n_est_values, mean_scores_by_n_est, 'o-', linewidth=2, markersize=10, color='blue')\n",
    "ax.set_xlabel('Number of Trees (n_estimators)', fontsize=11)\n",
    "ax.set_ylabel('Mean CV Accuracy', fontsize=11)\n",
    "ax.set_title('Effect of Number of Trees', fontsize=12, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Compare all three datasets\n",
    "ax = axes[1]\n",
    "models = ['Iris', 'Wine', 'Housing']\n",
    "best_scores = [grid_search_iris.best_score_, \n",
    "               grid_search_wine.best_score_, \n",
    "               grid_search_housing.best_score_]\n",
    "colors = ['#3498db', '#9b59b6', '#2ecc71']\n",
    "bars = ax.bar(models, best_scores, color=colors, alpha=0.7, edgecolor='black')\n",
    "ax.set_ylabel('Best CV Score', fontsize=12)\n",
    "ax.set_title('Best Tuned Model Performance', fontsize=12, fontweight='bold')\n",
    "ax.set_ylim(0.8, 1.0)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar, score in zip(bars, best_scores):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "            f'{score:.4f}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Hyperparameter tuning complete!\")\n",
    "print(\"üéØ Grid Search found optimal settings for each dataset\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186ffe30",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **9. ML Pipelines - Professional Workflow**\n",
    "\n",
    "**What is a Pipeline?**\n",
    "- Chains together preprocessing steps + model into one object\n",
    "- Ensures preprocessing is done consistently on train and test data\n",
    "- Prevents data leakage automatically\n",
    "- Makes code cleaner and more maintainable\n",
    "\n",
    "**Why Pipelines Matter:**\n",
    "1. **Prevents Data Leakage** - Scaler fits only on training fold in CV\n",
    "2. **Cleaner Code** - One `.fit()` instead of multiple steps\n",
    "3. **Easier Deployment** - Save entire pipeline as single object\n",
    "4. **Grid Search Integration** - Can tune preprocessing AND model together\n",
    "\n",
    "**Pipeline Structure:**\n",
    "```\n",
    "Pipeline([\n",
    "    ('scaler', StandardScaler()),      # Step 1: Scale features\n",
    "    ('classifier', RandomForest())     # Step 2: Train model\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b888cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"MACHINE LEARNING PIPELINES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ============================================================================\n",
    "# PART 1: Creating a Simple Pipeline for Iris\n",
    "# ============================================================================\n",
    "print(\"\\n1Ô∏è‚É£ BUILDING A PIPELINE FOR IRIS\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Create pipeline: Scaler ‚Üí Classifier\n",
    "# Pipeline automatically applies steps in sequence\n",
    "pipeline_iris = Pipeline([\n",
    "    ('scaler', StandardScaler()),           # Step 1: Normalize features\n",
    "    ('classifier', LogisticRegression(max_iter=200, random_state=42))  # Step 2: Train model\n",
    "])\n",
    "\n",
    "print(\"Pipeline created with 2 steps:\")\n",
    "print(\"  1. StandardScaler (normalize features)\")\n",
    "print(\"  2. LogisticRegression (classify)\")\n",
    "\n",
    "# Train pipeline with single fit() call\n",
    "# Internally: fits scaler on train data, transforms train data, trains classifier\n",
    "print(\"\\nTraining pipeline on Iris...\")\n",
    "pipeline_iris.fit(X_train_iris, y_train_iris)\n",
    "\n",
    "# Make predictions\n",
    "# Internally: transforms test data with fitted scaler, predicts with classifier\n",
    "y_pred_pipeline = pipeline_iris.predict(X_test_iris)\n",
    "\n",
    "# Evaluate\n",
    "accuracy_pipeline = accuracy_score(y_test_iris, y_pred_pipeline)\n",
    "print(f\"\\n‚úÖ Pipeline Accuracy: {accuracy_pipeline:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 2: Pipeline with Cross-Validation\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"2Ô∏è‚É£ PIPELINE WITH CROSS-VALIDATION\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Why pipelines are crucial for CV:\n",
    "# Without pipeline: Scaler sees ALL data ‚Üí DATA LEAKAGE\n",
    "# With pipeline: Each CV fold fits scaler only on that fold's training data\n",
    "\n",
    "print(\"Running 5-fold CV with pipeline (prevents data leakage)...\")\n",
    "\n",
    "# Cross-validate the entire pipeline\n",
    "cv_scores_pipeline = cross_val_score(\n",
    "    pipeline_iris,      # Entire pipeline\n",
    "    X_iris,             # RAW features (not scaled)\n",
    "    y_iris,\n",
    "    cv=5,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Cross-Validation Scores: {cv_scores_pipeline}\")\n",
    "print(f\"üìà Mean: {cv_scores_pipeline.mean():.4f} ¬± {cv_scores_pipeline.std():.4f}\")\n",
    "\n",
    "print(\"\\nüí° Pipeline automatically:\")\n",
    "print(\"   ‚Ä¢ Fits scaler on training folds only\")\n",
    "print(\"   ‚Ä¢ Transforms test folds with training statistics\")\n",
    "print(\"   ‚Ä¢ Prevents data leakage in every CV fold\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 3: Pipeline with Grid Search\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"3Ô∏è‚É£ PIPELINE + GRID SEARCH = ULTIMATE COMBO\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Create pipeline with Random Forest\n",
    "pipeline_rf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Define parameter grid\n",
    "# Use 'stepname__parameter' syntax to specify parameters\n",
    "param_grid_pipeline = {\n",
    "    'classifier__n_estimators': [50, 100, 150],     # RF parameter\n",
    "    'classifier__max_depth': [5, 10, None],         # RF parameter\n",
    "    'classifier__min_samples_split': [2, 5]         # RF parameter\n",
    "}\n",
    "\n",
    "print(f\"Testing {3 * 3 * 2} hyperparameter combinations...\")\n",
    "\n",
    "# Grid search on pipeline\n",
    "grid_search_pipeline = GridSearchCV(\n",
    "    pipeline_rf,\n",
    "    param_grid_pipeline,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nüîç Running Grid Search with Pipeline on Iris...\")\n",
    "grid_search_pipeline.fit(X_iris, y_iris)  # RAW data (pipeline handles scaling)\n",
    "\n",
    "print(f\"\\nüèÜ Best Parameters:\")\n",
    "for param, value in grid_search_pipeline.best_params_.items():\n",
    "    print(f\"   {param}: {value}\")\n",
    "print(f\"\\nüìä Best Score: {grid_search_pipeline.best_score_:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 4: Complete Pipeline for Wine Dataset\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"4Ô∏è‚É£ COMPLETE PIPELINE FOR WINE\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Build complete ML workflow\n",
    "pipeline_wine = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Train pipeline\n",
    "print(\"Training Wine classification pipeline...\")\n",
    "pipeline_wine.fit(X_train_wine, y_train_wine)\n",
    "\n",
    "# Evaluate\n",
    "y_pred_wine_pipeline = pipeline_wine.predict(X_test_wine)\n",
    "accuracy_wine_pipeline = accuracy_score(y_test_wine, y_pred_wine_pipeline)\n",
    "\n",
    "print(f\"‚úÖ Wine Pipeline Accuracy: {accuracy_wine_pipeline:.4f}\")\n",
    "\n",
    "# Show confusion matrix\n",
    "cm_wine_pipeline = confusion_matrix(y_test_wine, y_pred_wine_pipeline)\n",
    "print(\"\\nüìã Confusion Matrix:\")\n",
    "print(cm_wine_pipeline)\n",
    "\n",
    "# ============================================================================\n",
    "# PART 5: Regression Pipeline for Housing\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"5Ô∏è‚É£ REGRESSION PIPELINE FOR HOUSING\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Create regression pipeline\n",
    "pipeline_housing = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# Train on subset for speed (first 5000 samples)\n",
    "print(\"Training Housing regression pipeline...\")\n",
    "X_train_subset = X_train_housing[:5000]\n",
    "y_train_subset = y_train_housing[:5000]\n",
    "\n",
    "pipeline_housing.fit(X_train_subset, y_train_subset)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_housing_pipeline = pipeline_housing.predict(X_test_housing)\n",
    "mae_housing_pipeline = mean_absolute_error(y_test_housing, y_pred_housing_pipeline)\n",
    "r2_housing_pipeline = r2_score(y_test_housing, y_pred_housing_pipeline)\n",
    "\n",
    "print(f\"\\n‚úÖ Housing Pipeline Performance:\")\n",
    "print(f\"   MAE:  ${mae_housing_pipeline:.2f}\")\n",
    "print(f\"   R¬≤:   {r2_housing_pipeline:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 6: Pipeline Benefits Summary\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"6Ô∏è‚É£ WHY USE PIPELINES? COMPARISON\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "print(\"\\n‚ùå WITHOUT Pipeline (manual workflow):\")\n",
    "print(\"\"\"\n",
    "   # Step 1: Scale training data\n",
    "   scaler = StandardScaler()\n",
    "   X_train_scaled = scaler.fit_transform(X_train)\n",
    "   \n",
    "   # Step 2: Scale test data (RISK: might use test data accidentally)\n",
    "   X_test_scaled = scaler.transform(X_test)\n",
    "   \n",
    "   # Step 3: Train model\n",
    "   model = RandomForest()\n",
    "   model.fit(X_train_scaled, y_train)\n",
    "   \n",
    "   # Step 4: Predict\n",
    "   y_pred = model.predict(X_test_scaled)\n",
    "   \n",
    "   # Problem: Easy to make mistakes, especially in CV!\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚úÖ WITH Pipeline (professional workflow):\")\n",
    "print(\"\"\"\n",
    "   # Create pipeline\n",
    "   pipeline = Pipeline([\n",
    "       ('scaler', StandardScaler()),\n",
    "       ('model', RandomForest())\n",
    "   ])\n",
    "   \n",
    "   # Single fit handles everything correctly\n",
    "   pipeline.fit(X_train, y_train)\n",
    "   \n",
    "   # Single predict handles everything correctly\n",
    "   y_pred = pipeline.predict(X_test)\n",
    "   \n",
    "   # Benefits: Clean, safe, no data leakage possible!\n",
    "\"\"\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 7: Visualizing Pipeline Performance\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"7Ô∏è‚É£ PIPELINE PERFORMANCE VISUALIZATION\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Classification pipelines comparison\n",
    "ax = axes[0]\n",
    "datasets = ['Iris', 'Wine']\n",
    "accuracies = [accuracy_pipeline, accuracy_wine_pipeline]\n",
    "colors = ['#3498db', '#9b59b6']\n",
    "bars = ax.bar(datasets, accuracies, color=colors, alpha=0.7, edgecolor='black', width=0.5)\n",
    "ax.set_ylabel('Accuracy', fontsize=12)\n",
    "ax.set_title('Pipeline Performance - Classification', fontsize=13, fontweight='bold')\n",
    "ax.set_ylim(0.9, 1.0)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
    "            f'{height:.2%}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Regression pipeline\n",
    "ax = axes[1]\n",
    "metrics = ['MAE', 'R¬≤ Score']\n",
    "values = [mae_housing_pipeline, r2_housing_pipeline]\n",
    "colors = ['#e74c3c', '#2ecc71']\n",
    "bars = ax.bar(metrics, values, color=colors, alpha=0.7, edgecolor='black', width=0.5)\n",
    "ax.set_ylabel('Value', fontsize=12)\n",
    "ax.set_title('Pipeline Performance - Regression (Housing)', fontsize=13, fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "for bar, val in zip(bars, values):\n",
    "    height = bar.get_height()\n",
    "    if 'MAE' in bar.get_x():\n",
    "        label = f'${val:.2f}'\n",
    "    else:\n",
    "        label = f'{val:.4f}'\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "            label, ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Pipelines provide clean, safe, professional ML workflows!\")\n",
    "print(\"üéØ Always use pipelines in production code\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bad1892",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **10. Putting It All Together - Complete ML Workflow**\n",
    "\n",
    "**The Professional ML Process:**\n",
    "\n",
    "1. **Load & Explore Data** üìä\n",
    "   - Understand features, target, distributions\n",
    "   \n",
    "2. **Train/Test Split** ‚úÇÔ∏è\n",
    "   - Separate data for training and evaluation\n",
    "   \n",
    "3. **Build Pipeline** üîß\n",
    "   - Preprocessing + Model in one object\n",
    "   \n",
    "4. **Cross-Validation** üîÑ\n",
    "   - Robust performance estimate\n",
    "   \n",
    "5. **Hyperparameter Tuning** üéØ\n",
    "   - Find optimal settings with Grid Search\n",
    "   \n",
    "6. **Final Evaluation** ‚úÖ\n",
    "   - Test on held-out test set\n",
    "   \n",
    "7. **Analyze Results** üìà\n",
    "   - Confusion matrix, feature importance, visualizations\n",
    "\n",
    "Let's demonstrate the complete workflow on a new problem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c7ad61",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"COMPLETE ML WORKFLOW - IRIS SPECIES CLASSIFIER\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: Load and Explore Data\n",
    "# ============================================================================\n",
    "print(\"\\nüìä STEP 1: LOAD AND EXPLORE DATA\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Load Iris dataset (we already have it, but let's start fresh)\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X_full, y_full = iris.data, iris.target\n",
    "\n",
    "print(f\"Dataset: {len(X_full)} samples, {X_full.shape[1]} features\")\n",
    "print(f\"Classes: {iris.target_names}\")\n",
    "print(f\"Class distribution: {np.bincount(y_full)}\")\n",
    "print(f\"\\nFeature names: {iris.feature_names}\")\n",
    "print(f\"Feature ranges:\")\n",
    "for i, name in enumerate(iris.feature_names):\n",
    "    print(f\"  {name:20s}: {X_full[:, i].min():.2f} to {X_full[:, i].max():.2f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: Train/Test Split\n",
    "# ============================================================================\n",
    "print(\"\\n\\n‚úÇÔ∏è STEP 2: TRAIN/TEST SPLIT\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(\n",
    "    X_full, y_full, test_size=0.2, random_state=42, stratify=y_full\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train_full)} samples\")\n",
    "print(f\"Test set:     {len(X_test_full)} samples\")\n",
    "print(f\"Test set is HELD OUT until final evaluation!\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: Build Pipeline\n",
    "# ============================================================================\n",
    "print(\"\\n\\nüîß STEP 3: BUILD PIPELINE\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Create pipeline with preprocessing + model\n",
    "final_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "print(\"Pipeline created:\")\n",
    "print(\"  Step 1: StandardScaler\")\n",
    "print(\"  Step 2: RandomForestClassifier\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: Cross-Validation on Training Set\n",
    "# ============================================================================\n",
    "print(\"\\n\\nüîÑ STEP 4: CROSS-VALIDATION (Training Set Only)\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "print(\"Running 5-fold CV on training set...\")\n",
    "cv_scores = cross_val_score(\n",
    "    final_pipeline, \n",
    "    X_train_full, \n",
    "    y_train_full, \n",
    "    cv=5, \n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "print(f\"\\nCV Scores: {cv_scores}\")\n",
    "print(f\"Mean CV Accuracy: {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f}\")\n",
    "print(\"‚úÖ Model looks good on training data!\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: Hyperparameter Tuning\n",
    "# ============================================================================\n",
    "print(\"\\n\\nüéØ STEP 5: HYPERPARAMETER TUNING (Training Set Only)\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid_final = {\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__max_depth': [3, 5, 10],\n",
    "    'classifier__min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "print(f\"Testing {3 * 3 * 2} combinations with 5-fold CV...\")\n",
    "\n",
    "# Grid search\n",
    "grid_search_final = GridSearchCV(\n",
    "    final_pipeline,\n",
    "    param_grid_final,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(\"üîç Searching for best hyperparameters...\")\n",
    "grid_search_final.fit(X_train_full, y_train_full)\n",
    "\n",
    "print(f\"\\nüèÜ Best Parameters Found:\")\n",
    "for param, value in grid_search_final.best_params_.items():\n",
    "    print(f\"   {param}: {value}\")\n",
    "print(f\"\\nüìä Best CV Score: {grid_search_final.best_score_:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 6: Final Evaluation on Test Set\n",
    "# ============================================================================\n",
    "print(\"\\n\\n‚úÖ STEP 6: FINAL EVALUATION ON TEST SET\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Get best model from grid search\n",
    "best_model = grid_search_final.best_estimator_\n",
    "\n",
    "# NOW we use the test set for the first time\n",
    "y_pred_final = best_model.predict(X_test_full)\n",
    "\n",
    "# Calculate final metrics\n",
    "final_accuracy = accuracy_score(y_test_full, y_pred_final)\n",
    "final_cm = confusion_matrix(y_test_full, y_pred_final)\n",
    "\n",
    "print(f\"üéâ FINAL TEST ACCURACY: {final_accuracy:.2%}\")\n",
    "print(f\"\\nüìã Confusion Matrix:\")\n",
    "print(final_cm)\n",
    "print(f\"\\nüìà Classification Report:\")\n",
    "print(classification_report(y_test_full, y_pred_final, target_names=iris.target_names))\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 7: Analyze Results\n",
    "# ============================================================================\n",
    "print(\"\\n\\nüìà STEP 7: ANALYZE RESULTS\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Feature importance\n",
    "best_rf = best_model.named_steps['classifier']\n",
    "feature_importance = best_rf.feature_importances_\n",
    "\n",
    "print(\"üéØ Feature Importance:\")\n",
    "importance_pairs = sorted(zip(iris.feature_names, feature_importance), \n",
    "                         key=lambda x: x[1], reverse=True)\n",
    "for name, importance in importance_pairs:\n",
    "    bar = '‚ñà' * int(importance * 50)\n",
    "    print(f\"  {name:20s}: {bar} {importance:.3f}\")\n",
    "\n",
    "print(\"\\nüí° Insights:\")\n",
    "print(f\"  ‚Ä¢ Most important feature: {importance_pairs[0][0]}\")\n",
    "print(f\"  ‚Ä¢ Least important feature: {importance_pairs[-1][0]}\")\n",
    "print(f\"  ‚Ä¢ Model correctly classified {int(final_accuracy * len(y_test_full))}/{len(y_test_full)} test samples\")\n",
    "\n",
    "# Misclassified samples\n",
    "misclassified = np.where(y_pred_final != y_test_full)[0]\n",
    "if len(misclassified) > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è Misclassified Samples: {len(misclassified)}\")\n",
    "    for idx in misclassified[:3]:  # Show first 3\n",
    "        print(f\"  Sample {idx}: Predicted {iris.target_names[y_pred_final[idx]]}, \"\n",
    "              f\"Actually {iris.target_names[y_test_full[idx]]}\")\n",
    "else:\n",
    "    print(\"\\nüéâ PERFECT! All test samples classified correctly!\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 8: Comprehensive Visualization\n",
    "# ============================================================================\n",
    "print(\"\\n\\nüé® STEP 8: COMPREHENSIVE VISUALIZATION\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Confusion Matrix Heatmap\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "im = ax1.imshow(final_cm, cmap='Blues', aspect='auto')\n",
    "ax1.set_xticks(range(3))\n",
    "ax1.set_yticks(range(3))\n",
    "ax1.set_xticklabels(iris.target_names, rotation=45)\n",
    "ax1.set_yticklabels(iris.target_names)\n",
    "ax1.set_xlabel('Predicted')\n",
    "ax1.set_ylabel('Actual')\n",
    "ax1.set_title('Confusion Matrix', fontweight='bold')\n",
    "# Add text annotations\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        text = ax1.text(j, i, final_cm[i, j], ha='center', va='center', \n",
    "                       color='white' if final_cm[i, j] > final_cm.max()/2 else 'black',\n",
    "                       fontsize=14, fontweight='bold')\n",
    "plt.colorbar(im, ax=ax1)\n",
    "\n",
    "# 2. Feature Importance Bar Chart\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "features = [name.split()[0] for name in iris.feature_names]  # Shorten names\n",
    "importance_sorted = sorted(feature_importance, reverse=True)\n",
    "colors_sorted = plt.cm.viridis(np.linspace(0, 1, 4))\n",
    "bars = ax2.barh(range(4), importance_sorted, color=colors_sorted, edgecolor='black')\n",
    "ax2.set_yticks(range(4))\n",
    "ax2.set_yticklabels([name for name, _ in importance_pairs])\n",
    "ax2.set_xlabel('Importance')\n",
    "ax2.set_title('Feature Importance', fontweight='bold')\n",
    "ax2.invert_yaxis()\n",
    "for i, (bar, val) in enumerate(zip(bars, importance_sorted)):\n",
    "    ax2.text(val + 0.01, i, f'{val:.3f}', va='center', fontsize=10)\n",
    "\n",
    "# 3. CV Scores Distribution\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "cv_results = grid_search_final.cv_results_\n",
    "top_10_scores = sorted(cv_results['mean_test_score'])[-10:]\n",
    "ax3.hist(top_10_scores, bins=10, color='green', alpha=0.7, edgecolor='black')\n",
    "ax3.axvline(grid_search_final.best_score_, color='red', linestyle='--', linewidth=2, \n",
    "           label=f'Best: {grid_search_final.best_score_:.4f}')\n",
    "ax3.set_xlabel('CV Accuracy')\n",
    "ax3.set_ylabel('Frequency')\n",
    "ax3.set_title('Top 10 Model Scores', fontweight='bold')\n",
    "ax3.legend()\n",
    "\n",
    "# 4. Petal Length vs Width (colored by prediction)\n",
    "ax4 = fig.add_subplot(gs[1, 0])\n",
    "scatter = ax4.scatter(X_test_full[:, 2], X_test_full[:, 3], \n",
    "                     c=y_pred_final, cmap='viridis', s=100, alpha=0.6, edgecolor='black')\n",
    "ax4.set_xlabel('Petal Length')\n",
    "ax4.set_ylabel('Petal Width')\n",
    "ax4.set_title('Predictions: Petal Features', fontweight='bold')\n",
    "plt.colorbar(scatter, ax=ax4, ticks=[0, 1, 2], \n",
    "            label='Predicted Class')\n",
    "\n",
    "# 5. Sepal Length vs Width (colored by actual)\n",
    "ax5 = fig.add_subplot(gs[1, 1])\n",
    "scatter = ax5.scatter(X_test_full[:, 0], X_test_full[:, 1], \n",
    "                     c=y_test_full, cmap='viridis', s=100, alpha=0.6, edgecolor='black')\n",
    "ax5.set_xlabel('Sepal Length')\n",
    "ax5.set_ylabel('Sepal Width')\n",
    "ax5.set_title('Actual: Sepal Features', fontweight='bold')\n",
    "plt.colorbar(scatter, ax=ax5, ticks=[0, 1, 2], label='Actual Class')\n",
    "\n",
    "# 6. Model Comparison\n",
    "ax6 = fig.add_subplot(gs[1, 2])\n",
    "stages = ['CV on Train', 'Final Test']\n",
    "scores = [grid_search_final.best_score_, final_accuracy]\n",
    "bars = ax6.bar(stages, scores, color=['blue', 'green'], alpha=0.7, edgecolor='black')\n",
    "ax6.set_ylabel('Accuracy')\n",
    "ax6.set_title('Train vs Test Performance', fontweight='bold')\n",
    "ax6.set_ylim(0.9, 1.0)\n",
    "ax6.grid(axis='y', alpha=0.3)\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax6.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
    "            f'{height:.2%}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "# 7. Learning Curve (CV folds)\n",
    "ax7 = fig.add_subplot(gs[2, :])\n",
    "fold_scores = cv_scores\n",
    "folds = list(range(1, 6))\n",
    "ax7.plot(folds, fold_scores, 'o-', linewidth=2, markersize=10, color='blue', label='Fold Accuracy')\n",
    "ax7.axhline(fold_scores.mean(), color='red', linestyle='--', linewidth=2, \n",
    "           label=f'Mean: {fold_scores.mean():.4f}')\n",
    "ax7.fill_between(folds, fold_scores.mean() - fold_scores.std(), \n",
    "                fold_scores.mean() + fold_scores.std(),\n",
    "                alpha=0.2, color='red', label='¬±1 Std Dev')\n",
    "ax7.set_xlabel('Fold Number', fontsize=12)\n",
    "ax7.set_ylabel('Accuracy', fontsize=12)\n",
    "ax7.set_title('Cross-Validation Consistency', fontsize=13, fontweight='bold')\n",
    "ax7.set_xticks(folds)\n",
    "ax7.legend()\n",
    "ax7.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('üéâ Complete ML Workflow: Iris Classification üéâ', \n",
    "            fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# FINAL SUMMARY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üéì COMPLETE ML WORKFLOW SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\"\"\n",
    "‚úÖ Step 1: Loaded {len(X_full)} samples with {X_full.shape[1]} features\n",
    "‚úÖ Step 2: Split into {len(X_train_full)} train, {len(X_test_full)} test samples\n",
    "‚úÖ Step 3: Built pipeline with StandardScaler + RandomForest\n",
    "‚úÖ Step 4: Cross-validated on training set ‚Üí {cv_scores.mean():.4f} accuracy\n",
    "‚úÖ Step 5: Tuned hyperparameters ‚Üí {grid_search_final.best_score_:.4f} CV accuracy\n",
    "‚úÖ Step 6: Evaluated on test set ‚Üí {final_accuracy:.2%} accuracy\n",
    "‚úÖ Step 7: Analyzed feature importance and misclassifications\n",
    "‚úÖ Step 8: Created comprehensive visualizations\n",
    "\n",
    "üèÜ FINAL MODEL PERFORMANCE:\n",
    "   ‚Ä¢ Test Accuracy: {final_accuracy:.2%}\n",
    "   ‚Ä¢ Correctly classified: {int(final_accuracy * len(y_test_full))}/{len(y_test_full)} samples\n",
    "   ‚Ä¢ Best hyperparameters: {grid_search_final.best_params_}\n",
    "   \n",
    "üéØ KEY TAKEAWAYS:\n",
    "   1. Always split data BEFORE any analysis\n",
    "   2. Use pipelines to prevent data leakage\n",
    "   3. Tune hyperparameters with cross-validation\n",
    "   4. Evaluate on test set ONLY ONCE at the end\n",
    "   5. Analyze results to understand model behavior\n",
    "   \n",
    "üí° THIS IS THE PROFESSIONAL ML WORKFLOW!\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"‚ú® Chapter 04: scikit-learn Machine Learning - COMPLETE! ‚ú®\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b12c0eb",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"projects\"></a>\n",
    "## üöÄ Chapter Completed! Now Practice with Projects\n",
    "\n",
    "### üéâ Congratulations! You've Mastered scikit-learn Basics!\n",
    "\n",
    "### üìù Recommended Projects (in order):\n",
    "\n",
    "#### 1. **Project 03: Classification** ‚≠ê‚≠ê‚≠ê Intermediate\n",
    "**Link:** [Open Project 03](../projects/Project_03_Classification.md)\n",
    "\n",
    "**Time:** 4-5 hours\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Project 04: Regression** ‚≠ê‚≠ê‚≠ê Intermediate\n",
    "**Link:** [Open Project 04](../projects/Project_04_Regression.md)\n",
    "\n",
    "**Time:** 3-4 hours\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Project 05: Clustering & PCA** ‚≠ê‚≠ê Intermediate\n",
    "**Link:** [Open Project 05](../projects/Project_05_Clustering_PCA.md)\n",
    "\n",
    "**Time:** 3 hours\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. **Project 06: End-to-End ML Pipeline** ‚≠ê‚≠ê‚≠ê‚≠ê Advanced\n",
    "**Link:** [Open Project 06](../projects/Project_06_EndToEnd.md)\n",
    "\n",
    "**Time:** 6-8 hours\n",
    "\n",
    "---\n",
    "\n",
    "## üéì You're Now Ready for Real ML Projects!\n",
    "\n",
    "### üí° Next Steps:\n",
    "1. Complete Projects 03-06 to build your ML portfolio\n",
    "2. Participate in Kaggle competitions\n",
    "3. Build your own ML projects with real data\n",
    "4. Learn advanced topics: Deep Learning, NLP, Computer Vision\n",
    "\n",
    "---\n",
    "\n",
    "## üîó Navigation\n",
    "\n",
    "- **Previous**: [Chapter 03: Matplotlib](03_Matplotlib_Visualization.ipynb)\n",
    "- **Home**: [START HERE](../START_HERE.md)\n",
    "- **Index**: [Main Index](../index.md)\n",
    "- **All Projects**: [Projects Overview](../projects/README.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
